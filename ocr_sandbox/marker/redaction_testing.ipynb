{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pdfplumber\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# import pytesseract as pyt\n",
    "import fitz\n",
    "import pymupdf\n",
    "# from pdf2image import convert_from_path\n",
    "# from PIL import Image, ImageEnhance, ImageFilter\n",
    "# import cv2\n",
    "# from tesserocr import PyTessBaseAPI, RIL\n",
    "# import tesserocr\n",
    "import json\n",
    "import pprint\n",
    "import re\n",
    "from dotenv import find_dotenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# marker functions\n",
    "from marker.converters.ocr import OCRConverter\n",
    "from marker.converters.pdf import PdfConverter\n",
    "from marker.models import create_model_dict\n",
    "from marker.config.parser import ConfigParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "torch.zeros(1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile = \"page1-cli-ocr-force-strip-chars\"\n",
    "directory = \"/content/testing/\" + testfile + \".pdf\"\n",
    "\n",
    "config = {\n",
    "    \"output_format\": \"json\",\n",
    "    \"OCRJSONRenderer_extract_images\": \"True\",\n",
    "    \"disable_image_extraction\": \"True\",\n",
    "    \"DEBUG\":\"True\",\n",
    "    \"force_ocr\":\"True\",\n",
    "    \"strip_existing_ocr\": \"True\"\n",
    "}\n",
    "config_parser = ConfigParser(config)\n",
    "converter = OCRConverter(\n",
    "    config=config_parser.generate_config_dict(),\n",
    "    artifact_dict=create_model_dict(),\n",
    ")\n",
    "rendered = converter(directory)\n",
    "\n",
    "output_filename = \"/content/testing/\" + \"marker-\" + testfile + \".json\"\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(rendered.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if individual file is repaired (before uploading to marker-pdf)\n",
    "# quickcheckname = \"textract_test\"\n",
    "# doc = pymupdf.open(\"./docs_to_write_on/\"+ quickcheckname + \".pdf\")\n",
    "# print(doc.can_save_incrementally())\n",
    "# doc.close()\n",
    "# page=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marker testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file-list to process\n",
    "\n",
    "pdfolder = \"./docs_to_write_on/\"\n",
    "jsonfolder = \"./jsons_to_read/\"\n",
    "nameslist = set([filename[:-4] for filename in os.listdir(pdfolder)])   # read all files in directory and cut off extensions (keep file names only), set-type object for faster comparison later\n",
    "print(nameslist)\n",
    "\n",
    "# use this portion to opt in/out files to be run later\n",
    "\n",
    "opt_out = {'page1test'}\n",
    "nameslist = [name for name in nameslist if name not in opt_out]\n",
    "# print(nameslist)   \n",
    "\n",
    "#replace cutting off 'marker-' with regex\n",
    "verificationset = set([filename[7:] for filename in [filename[:-5] for filename in os.listdir(jsonfolder)]]).symmetric_difference(nameslist)   # cut off marker- prefix and .json extension from json files and compare to namelist sets to verify no issues\n",
    "if verificationset == opt_out:\n",
    "    verificationset = set()\n",
    "print(verificationset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify files before uploading to marker or opening with PyMuPDF\n",
    "\n",
    "def check_ok_for_marker(filename, filedir):\n",
    "    \n",
    "    init_file = filedir + filename + \".pdf\"\n",
    "    doc = pymupdf.open(init_file)\n",
    "\n",
    "    if not doc.can_save_incrementally():\n",
    "\n",
    "        print(f'File: \"{filename}\" unwritable. Fixing...')\n",
    "\n",
    "        new_file = filedir + filename + \"-fixed\" + \".pdf\"\n",
    "        doc.save(new_file, garbage=4,deflate=True)\n",
    "        doc.close()\n",
    "        page=None\n",
    "        os.remove(init_file)\n",
    "        os.rename(new_file,init_file)\n",
    "    else:\n",
    "        print('Nothing to fix!')\n",
    "\n",
    "if len(verificationset)==0 :   # change this to check only files that are outside the verificationlist\n",
    "    for pdf_file in nameslist:\n",
    "        check_ok_for_marker(pdf_file,pdfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renderedlist = []\n",
    "for json_file in nameslist:\n",
    "    with open(jsonfolder + \"marker-\" + json_file + \".json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        renderedlist.append(json.load(f)['children'])\n",
    "\n",
    "# for json_file in renderedlist:\n",
    "#   pprint.pprint(json_file, indent=2)\n",
    "print(renderedlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve specific defined coordinates from JSON, \"flatten\" data\n",
    "\n",
    "# Marker-defined categories (specifically leaves only) to extract from marker output JSON. Parse through the output JSON to find new leaf categories to add for extraction\n",
    "leaf_categories_with_text = ['Line','Text','TextInlineMath','Caption','ListItem','SectionHeader','TableCell', 'PageFooter','PageHeader']\n",
    "leaf_categories_to_retrieve = ['Picture','TableGroup','Equation', 'Figure', 'Handwriting']\n",
    "\n",
    "# For data retrieved from parsing with the full marker PDF model. Recursive function to retrieve all coordinates and text of identified objects\n",
    "def retrieve_specific_boxes_and_flatten(treelist,pull_polygons,pull_text):\n",
    "  # recursive function to pick up all the coordinates, and all HTML text from specifically defined configurations of nested items\n",
    "  coordinates = {}\n",
    "  htmtext = {}\n",
    "  \n",
    "  for nitem,item in enumerate(treelist):\n",
    "    newpoly = {}\n",
    "    newtext = {}\n",
    "    if (item['children']):\n",
    "      # newpoly = {'size':[tuple(point) for point in item['polygon']]}\n",
    "      newchildren = item['children']\n",
    "      retr_coords,retr_text = retrieve_specific_boxes_and_flatten(newchildren,pull_polygons,pull_text)\n",
    "      newpoly.update(retr_coords)\n",
    "      newtext.update(retr_text)\n",
    "      if item['block_type']=='Page':\n",
    "        newitem_poly = {int(re.search(r\"/page/(\\d+)/\", item['id']).group(1)):newpoly}\n",
    "        newitem_text = {int(re.search(r\"/page/(\\d+)/\", item['id']).group(1)):newtext}\n",
    "      else: \n",
    "        newitem_poly = newpoly\n",
    "        newitem_text = newtext\n",
    "    else:\n",
    "      if (item['block_type'] in pull_polygons) or (item['block_type'] in pull_text) :\n",
    "        newpoly = item['polygon']\n",
    "        newpoly = [tuple(point) for point in newpoly]\n",
    "        newitem_poly = {item['id']:newpoly}\n",
    "        if item['block_type'] in pull_text:\n",
    "          newtext = item['html']\n",
    "          newitem_text = {item['id']:newtext}\n",
    "        else:\n",
    "          newitem_text = {}\n",
    "      else: \n",
    "        newitem_poly = {}\n",
    "        newitem_text = {}\n",
    "    coordinates.update(newitem_poly)\n",
    "    htmtext.update(newitem_text)\n",
    "  return (coordinates,htmtext)\n",
    "\n",
    "# For data retrieved from parsing with the OCR-ONLY marker PDF model with the --keep-chars flag active. Recursive function to retrieve all coordinates and \n",
    "# text of identified objects. The difference from the full model function are the 'Char' objects. They do not have a 'children' attribute and the retrieval throws an error\n",
    "# (could technically only use this function but I like to have them differentiated)\n",
    "def ocr_retrieve_specific_boxes_and_flatten(treelist,pull_polygons,pull_text):\n",
    "  # recursive function to pick up all the coordinates from specifically defined configurations of nested items\n",
    "  coordinates = {}\n",
    "  htmtext = {}\n",
    "  \n",
    "  for nitem,item in enumerate(treelist):\n",
    "    newpoly = {}\n",
    "    newtext = {}\n",
    "    if (item['block_type'] == 'Char'):\n",
    "        newpoly = item['polygon']\n",
    "        newpoly = [tuple(point) for point in newpoly]\n",
    "        newitem_poly = {item['id']:newpoly}\n",
    "        newtext = item['text']\n",
    "        newitem_text = {item['id']:newtext}\n",
    "    else:\n",
    "        if (item['children']):\n",
    "            # newpoly = {'size':[tuple(point) for point in item['polygon']]}\n",
    "            newchildren = item['children']\n",
    "            retr_coords,retr_text = ocr_retrieve_specific_boxes_and_flatten(newchildren,pull_polygons,pull_text)\n",
    "            newpoly.update(retr_coords)\n",
    "            newtext.update(retr_text)\n",
    "            if item['block_type']=='Page':\n",
    "                newitem_poly = {int(re.search(r\"/page/(\\d+)/\", item['id']).group(1)):newpoly}\n",
    "                newitem_text = {int(re.search(r\"/page/(\\d+)/\", item['id']).group(1)):newtext}\n",
    "            else: \n",
    "                newitem_poly = newpoly\n",
    "                newitem_text = newtext\n",
    "        else:\n",
    "            if (item['block_type'] in pull_polygons) or (item['block_type'] in pull_text) :\n",
    "                newpoly = item['polygon']\n",
    "                newpoly = [tuple(point) for point in newpoly]\n",
    "                newitem_poly = {item['id']:newpoly}\n",
    "                if item['block_type'] in pull_text:\n",
    "                    newtext = item['html']\n",
    "                    newitem_text = {item['id']:newtext}\n",
    "                else:\n",
    "                    newitem_text = {}\n",
    "            else: \n",
    "                newitem_poly = {}\n",
    "                newitem_text = {}\n",
    "    coordinates.update(newitem_poly)\n",
    "    htmtext.update(newitem_text)\n",
    "  return (coordinates,htmtext)\n",
    "\n",
    "\n",
    "\n",
    "renderedboxes = []\n",
    "renderedtext = []\n",
    "\n",
    "for name,red_lines in zip(nameslist,renderedlist):\n",
    "  if re.search('(chars)', name):\n",
    "    all_boxes,all_text = ocr_retrieve_specific_boxes_and_flatten(red_lines,leaf_categories_to_retrieve,leaf_categories_with_text)\n",
    "  else:\n",
    "    all_boxes,all_text = retrieve_specific_boxes_and_flatten(red_lines,leaf_categories_to_retrieve,leaf_categories_with_text)\n",
    "\n",
    "\n",
    "  renderedboxes.append(all_boxes)\n",
    "  renderedtext.append(all_text) \n",
    "\n",
    "for boxes,texts in zip(renderedboxes,renderedtext):\n",
    "   display(boxes)\n",
    "   display(texts)\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "\n",
    "# old JSON processing function, workd for simple OCR model, fails for Full model\n",
    "\n",
    "# def retrieve_all_boxes(treelist):\n",
    "#   # recursive function to pick up all the coordinates from any configuration of nested items\n",
    "#   newdict = {}\n",
    "#   # location = location + \" \" + str(nitem)\n",
    "#   # all_boxes.update({location:item['polygon']})\n",
    "#   for nitem,item in enumerate(treelist):\n",
    "#     if (item['children']):\n",
    "#       newpoly = {'size':[tuple(point) for point in item['polygon']]}\n",
    "#       newchildren = item['children']\n",
    "#       newpoly.update(retrieve_all_boxes(newchildren))\n",
    "#       if item['block_type']=='Page':\n",
    "#         newid = int(re.search(r\"/page/(\\d+)/\", item['id']).group(1))\n",
    "#       else: newid = item['id']\n",
    "#     else:\n",
    "#       newpoly = item['polygon']\n",
    "#       newpoly = [tuple(point) for point in newpoly]\n",
    "#       newid = item['id']\n",
    "   \n",
    "#     newdict.update({newid:newpoly})\n",
    "#   return newdict\n",
    "\n",
    "# all_boxes = retrieve_all_boxes(red_lines)\n",
    "# display(all_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write coordinate boxes to PDF\n",
    "\n",
    "\n",
    "def add_boxes(filename, filedir, annotations):\n",
    "\n",
    "  # open current document\n",
    "  init_file = filedir + filename + \".pdf\"\n",
    "  doc = pymupdf.open(init_file)\n",
    "\n",
    "  # check file health and save as new file (fixes marker-pdf PIL errors and PyMuPDF 'code=4' errors)\n",
    "  if not doc.can_save_incrementally():\n",
    "    print(f'File: \"{filename}\" unwritable. Fixing...')\n",
    "    # filename = filename + \"-fixed\"\n",
    "    new_file = filedir + filename + \"-fixed\" + \".pdf\"\n",
    "    doc.save(new_file, garbage=4,deflate=True)\n",
    "    doc.close()\n",
    "    page=None\n",
    "    os.remove(init_file)\n",
    "    os.rename(new_file,init_file)\n",
    "    doc = pymupdf.open(init_file)\n",
    "  \n",
    "  for i,page in enumerate(doc):\n",
    "    lines = annotations[i]\n",
    "    nannots = len(lines)\n",
    "    for ncoord,coords in enumerate(lines.items()):\n",
    "      print(f\"Page {i}: Adding annotation {ncoord} / {nannots}\",end='\\r')\n",
    "      annot = page.add_polygon_annot(coords[1])\n",
    "      annot.set_colors(stroke=(0.416, 0.416, 1))\n",
    "      annot.update()\n",
    "      doc.saveIncr()\n",
    "  doc.close()\n",
    "  page=None\n",
    "  print(f'\"{filename}\" annotated.')\n",
    "\n",
    "\n",
    "def print_retrieved_text(texttoprint):\n",
    "  for item in texttoprint.values():\n",
    "    for textblock in item.values():\n",
    "      print(re.sub( \"<(\\w+)([\\s\\-\\w='\\\":/\\.]+)?>\" ,\"\",re.sub( \"<(/\\w+)([\\s\\w=':/\\.]+)?>\" ,\"\",textblock)))\n",
    "\n",
    "for name,boxes,texts in zip(nameslist,renderedboxes,renderedtext):\n",
    "  add_boxes(name, pdfolder, boxes)\n",
    "  print_retrieved_text(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kofax: Pulling signatures from processed PDF \n",
    "(using Kofax, transform to Word and then back to PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, fitz, unicodedata\n",
    "\n",
    "# ---- helpers ---- \n",
    "def norm(s):\n",
    "    s = unicodedata.normalize('NFKC', str(s))\n",
    "    return s.replace('\\u00B7','.')  # middle dot → '.'\n",
    "\n",
    "# τίτλοι που ενεργοποιούν Wipe-Βand\n",
    "HEAD_TRIGGERS = [\n",
    "  'ΟΙ ΣΥΜΒΑΛΛΟΜΕΝΟΙ', 'Ο ΣΥΜΒΑΛΛΟΜΕΝΟΣ', 'Η ΣΥΜΒΑΛΛΟΜΕΝΗ',\n",
    "  'Ο ΣΥΝΕΤΑΙΡΟΣ ΠΙΣΤΟΥΧΟΣ', 'ΟΙ ΣΥΝΟΦΕΙΛΕΤΗΣ', 'Ο/ΟΙ ΣΥΝΟΦΕΙΛΕΤΗΣ/ΕΣ',\n",
    "  'Ο/ΟΙ ΕΓΓΥΗΤΗΣ/ΕΣ', 'Ο ΕΓΓΥΗΤΗΣ', 'Ο ΟΦΕΙΛΕΤΗΣ', 'Ο/ΟΙ ΟΦΕΙΛΕΤΗΣ/ΕΣ'\n",
    "]\n",
    "\n",
    "def text_blocks(page):\n",
    "    # rawdict → blocks (text/images) με bbox\n",
    "    data = page.get_text('rawdict')\n",
    "    return data.get('blocks', []) if isinstance(data, dict) else []\n",
    "\n",
    "def find_heading_band(page, side_margin=10, top_offset=6):\n",
    "    # ψάξε αν υπάρχει τίτλος-κλειδί στη σελίδα και γύρνα ζώνη (x0,y0,x1,y1)\n",
    "    W,H = page.rect.width, page.rect.height\n",
    "    best_y = None\n",
    "    for b in text_blocks(page):\n",
    "        if b.get('type') != 0: continue  # μόνο text blocks\n",
    "        for l in b.get('lines', []):\n",
    "            line_text = ' '.join([s.get('text','') for s in l.get('spans',[])])\n",
    "            T = norm(line_text).upper().strip()\n",
    "            for key in HEAD_TRIGGERS:\n",
    "                if key in T:\n",
    "                    # πάρε bbox της γραμμής\n",
    "                    xs=[]; ys=[]\n",
    "                    for s in l.get('spans', []):\n",
    "                        (x0,y0,x1,y1) = s.get('bbox', (None,None,None,None))\n",
    "                        if x0 is None: continue\n",
    "                        xs += [x0,x1]; ys += [y0,y1]\n",
    "                    if xs and ys:\n",
    "                        y_line = max(ys)  # κάτω άκρη γραμμής\n",
    "                        best_y = y_line if best_y is None else min(best_y, y_line)\n",
    "    if best_y is None: return None\n",
    "    x0 = page.rect.x0 + side_margin\n",
    "    y0 = best_y + top_offset\n",
    "    x1 = page.rect.x1 - side_margin\n",
    "    y1 = page.rect.y1 - 8\n",
    "    return (x0,y0,x1,y1) if y0 < y1 else None\n",
    "\n",
    "def image_boxes_in_band(page, band=None, bottom_ratio=0.35):\n",
    "    boxes = []\n",
    "    W,H = page.rect.width, page.rect.height\n",
    "    bottom_y = H*(1.0-bottom_ratio)\n",
    "    for b in text_blocks(page):\n",
    "        if b.get('type') == 1:  # image\n",
    "            (x0,y0,x1,y1) = b.get('bbox', (None,None,None,None))\n",
    "            if x0 is None: continue\n",
    "            # κριτήρια: (i) τέμνει band ή (ii) βρίσκεται στο κάτω Χ% της σελίδας\n",
    "            in_bottom = (y0 >= bottom_y) or (y1 >= bottom_y)\n",
    "            intersects_band = False\n",
    "            if band is not None:\n",
    "                bx0,by0,bx1,by1 = band\n",
    "                intersects_band = not (x1<bx0 or x0>bx1 or y1<by0 or y0>by1)\n",
    "            if intersects_band or in_bottom:\n",
    "                boxes.append((x0,y0,x1,y1))\n",
    "    return boxes\n",
    "\n",
    "def redact_pdf(input_pdf, output_pdf, do_wipe=True, do_images=True, side_margin=10, top_offset=6, bottom_ratio=0.35, fill='white', draw_labels=False):\n",
    "    rgb=(1,1,1) if str(fill).lower()=='white' else (0,0,0)\n",
    "    doc = fitz.open(input_pdf)\n",
    "    for pno in range(len(doc)):\n",
    "        page = doc[pno]\n",
    "        band = find_heading_band(page, side_margin=side_margin, top_offset=top_offset) if do_wipe else None\n",
    "        if band:\n",
    "            r = fitz.Rect(band)\n",
    "            page.add_redact_annot(r, text=('[SIGN-BAND]' if draw_labels else None), fill=rgb)\n",
    "        if do_images:\n",
    "            for (x0,y0,x1,y1) in image_boxes_in_band(page, band=band, bottom_ratio=bottom_ratio):\n",
    "                r = fitz.Rect(x0,y0,x1,y1)\n",
    "                page.add_redact_annot(r, text=('[IMG]' if draw_labels else None), fill=rgb)\n",
    "        page.apply_redactions()\n",
    "    doc.save(output_pdf, garbage=4, deflate=True)\n",
    "    doc.close()\n",
    "\n",
    "\n",
    "redact_pdf('test_text_and_signaturesdoc.pdf',\"out_signzones.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure: DocumentIntelligence for OCR\n",
    "\n",
    "and integrating an NER model on the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path='./config/.env')\n",
    "\n",
    "AZURE_ENDPOINT = os.getenv('AZURE_ENDPOINT')\n",
    "AZURE_KEY = os.getenv('AZURE_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_CONFIG = {\n",
    "    \"endpoint\" : AZURE_ENDPOINT,\n",
    "    \"key\" : AZURE_KEY\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TesserOCR: Testing library to get coordinates\n",
    "\n",
    "After pre-OCR-ing with Tungsten/Kofax PowerPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Tesseract + output images (i think)\n",
    "\n",
    "# Define Tesseract exe location\n",
    "pyt.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "pyt.get_languages()\n",
    "\n",
    "current_file = \"testtest.pdf\"\n",
    "\n",
    "\n",
    "\n",
    "def ocr_scanned_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    images = convert_from_path(pdf_path)    \n",
    "    for i, image in enumerate(images):\n",
    "        page_text = pyt.image_to_string(image, lang=\"ell\",config=\"--psm 4 --oem 3 -c tessedit_write_images=true\")      \n",
    "        print(f\"OCR result for page {i+1}: {page_text}\")\n",
    "        # text += f\"--- Page {i+1} ---\\n{page_text}\\n\\n\"\n",
    "    return text\n",
    "\n",
    "\n",
    "ocr_scanned_pdf(current_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite initial file to contain all coordinates of identified words\n",
    "\n",
    "\n",
    "insertions = []\n",
    "\n",
    "# open document\n",
    "input_pdf = \"testtest.pdf\"\n",
    "doc = fitz.open(input_pdf)\n",
    "\n",
    "# insert here transform pdf to image\n",
    "images = convert_from_path(input_pdf)\n",
    "print(images)\n",
    "\n",
    "\n",
    "def transform_coords(box):\n",
    "    # assume of dict format with {'x':x,'y':y,'w':w,'h':h}\n",
    "    x1 = box['x']\n",
    "    y1 = box['y']\n",
    "    w = box['w']\n",
    "    h = box['h']\n",
    "    x2 = x1+w\n",
    "    y2 = y1+h\n",
    "\n",
    "    # with polygon annotation:\n",
    "    coordinates_pdf = [(x1*scale_x - 2,y1*scale_y - 2),(x2*scale_x + 2,y1*scale_y - 2), (x2*scale_x + 2,y2*scale_y + 2),(x1*scale_x - 2,y2*scale_y + 2)]\n",
    "\n",
    "    # with redact annotation:\n",
    "\n",
    "\n",
    "    return coordinates_pdf\n",
    "\n",
    "\n",
    "for j,image in enumerate(images):\n",
    "\n",
    "    insertions_temp_dict = {}\n",
    "\n",
    "    with PyTessBaseAPI(path=r'C:\\Program Files\\Tesseract-OCR\\tessdata', lang='ell') as api:\n",
    "\n",
    "\n",
    "        api.SetImage(image)\n",
    "\n",
    "        # get all sizes\n",
    "        currentpage = j\n",
    "        imgsize = image.size\n",
    "        page = doc[currentpage]\n",
    "        scale_x = page.rect.width / imgsize[0]\n",
    "        scale_y = page.rect.height / imgsize[1]\n",
    "\n",
    "        boxes = api.GetComponentImages(RIL.TEXTLINE, True)\n",
    "        total_items = len(boxes)\n",
    "        print('Found {} textline image components.'.format(total_items))\n",
    "        for i, (im, box, _, _) in enumerate(boxes):\n",
    "\n",
    "            api.SetRectangle(box['x'], box['y'], box['w'], box['h'])\n",
    "            ocrResult = api.GetUTF8Text()\n",
    "            conf = api.MeanTextConf()\n",
    "\n",
    "            # create box visually on PDF and add embellishments\n",
    "            pdf_transformed_coordinates = transform_coords(box)\n",
    "            # print(pdf_transformed_coordinates)\n",
    "            print(pdf_transformed_coordinates)\n",
    "            annot = page.add_polygon_annot(pdf_transformed_coordinates)\n",
    "            annot.set_colors(stroke=(0.416, 0.416, 1))\n",
    "            annot.update()\n",
    "\n",
    "            # # add text for visual representation\n",
    "            # text_rect = fitz.Rect(pdf_transformed_coordinates[0][0],pdf_transformed_coordinates[0][1],pdf_transformed_coordinates[2][0],pdf_transformed_coordinates[2][1])\n",
    "            # # text_rect = fitz.Rect(100,100,100,100)\n",
    "            # page.insert_textbox(\n",
    "            #     text_rect,\n",
    "            #     ocrResult,\n",
    "            #     fontsize=3,\n",
    "            #     fontname=\"helv\",\n",
    "            #     color=(0, 0, 0),   # black text\n",
    "            #     align=1            # center align\n",
    "            # )\n",
    "\n",
    "            # insertions_temp_dict.update({i:inserted})\n",
    "            doc.saveIncr()\n",
    "            print(f\"\\rProgress: {i+1}/{total_items}\",\"\\r\",end=\"\")\n",
    "    insertions.append(insertions_temp_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "doc.close()\n",
    "page = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untangling Char coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= {'/page/0/Char/309': [(59.981864717805415, 287.13748905389093),\n",
    "(59.981864717805415, 287.51234217276027),\n",
    "(60.3567513722917, 287.51234217276027),\n",
    "(60.3567513722917, 287.13748905389093)],\n",
    "'/page/0/Char/310': [(59.981864717805415, 287.13748905389093),\n",
    "(59.981864717805415, 287.51234217276027),\n",
    "(60.3567513722917, 287.51234217276027),\n",
    "(60.3567513722917, 287.13748905389093)],\n",
    "'/page/0/Char/311': [(133.08476234263077, 288.2620484104989),\n",
    "(154.82818830283523, 288.2620484104989),\n",
    "(154.82818830283523, 293.1351389557999),\n",
    "(133.08476234263077, 293.1351389557999)],\n",
    "'/page/0/Char/312': [(140.58249543235644, 288.2620484104989),\n",
    "(153.3286416848901, 288.2620484104989),\n",
    "(153.3286416848901, 293.1351389557999),\n",
    "(140.58249543235644, 293.1351389557999)],\n",
    "'/page/0/Char/313': [(149.20488848554098, 288.2620484104989),\n",
    "(159.32682815667062, 288.2620484104989),\n",
    "(159.32682815667062, 293.1351389557999),\n",
    "(149.20488848554098, 293.1351389557999)],\n",
    "'/page/0/Char/314': [(149.20488848554098, 288.2620484104989),\n",
    "(160.82637477461577, 288.2620484104989),\n",
    "(160.82637477461577, 293.1351389557999),\n",
    "(149.20488848554098, 293.1351389557999)],\n",
    "'/page/0/Char/315': [(151.45420841245866, 288.2620484104989),\n",
    "(160.0766014656432, 288.2620484104989),\n",
    "(160.0766014656432, 293.5099920746692),\n",
    "(151.45420841245866, 293.5099920746692)],\n",
    "'/page/0/Char/316': [(156.32773492078036, 287.88719529162955),\n",
    "(167.1994479008826, 287.88719529162955),\n",
    "(167.1994479008826, 293.5099920746692),\n",
    "(156.32773492078036, 293.5099920746692)],\n",
    "'/page/0/Char/317': [(154.45330164834894, 287.88719529162955),\n",
    "(165.69990128293745, 287.88719529162955),\n",
    "(165.32501462845116, 293.5099920746692),\n",
    "(154.07841499386265, 293.5099920746692)],\n",
    "'/page/0/Char/318': [(157.4523948842392, 287.88719529162955),\n",
    "(168.32410786434144, 287.88719529162955),\n",
    "(168.32410786434144, 293.5099920746692),\n",
    "(157.4523948842392, 293.5099920746692)],\n",
    "'/page/0/Char/319': [(155.57796161180778, 288.2620484104989),\n",
    "(163.82546801050603, 288.2620484104989),\n",
    "(163.82546801050603, 293.1351389557999),\n",
    "(155.57796161180778, 293.1351389557999)],\n",
    "'/page/0/Char/320': [(152.9537550304038, 288.2620484104989),\n",
    "(163.82546801050603, 288.2620484104989),\n",
    "(163.82546801050603, 293.1351389557999),\n",
    "(152.9537550304038, 293.1351389557999)],\n",
    "'/page/0/Char/321': [(152.9537550304038, 288.2620484104989),\n",
    "(162.7008080470472, 288.2620484104989),\n",
    "(162.7008080470472, 293.5099920746692),\n",
    "(152.9537550304038, 293.5099920746692)],\n",
    "'/page/0/Char/322': [(153.70352833937636, 288.2620484104989),\n",
    "(160.82637477461577, 288.2620484104989),\n",
    "(160.82637477461577, 293.5099920746692),\n",
    "(153.70352833937636, 293.5099920746692)],\n",
    "'/page/0/Char/323': [(149.57977514002724, 288.2620484104989),\n",
    "(159.7017148111569, 288.2620484104989),\n",
    "(159.7017148111569, 293.5099920746692),\n",
    "(149.57977514002724, 293.5099920746692)],\n",
    "'/page/0/Char/324': [(149.20488848554098, 288.2620484104989),\n",
    "(159.7017148111569, 288.2620484104989),\n",
    "(159.7017148111569, 293.5099920746692),\n",
    "(149.20488848554098, 293.5099920746692)],\n",
    "'/page/0/Char/325': [(152.57886837591752, 288.2620484104989),\n",
    "(162.3259213925609, 288.2620484104989),\n",
    "(162.3259213925609, 293.1351389557999),\n",
    "(152.57886837591752, 293.1351389557999)],\n",
    "'/page/0/Char/326': [(147.70534186759582, 288.2620484104989),\n",
    "(158.95194150218435, 288.2620484104989),\n",
    "(158.95194150218435, 293.5099920746692),\n",
    "(147.70534186759582, 293.5099920746692)],\n",
    "'/page/0/Char/327': [(148.8300018310547, 288.2620484104989),\n",
    "(157.4523948842392, 288.2620484104989),\n",
    "(157.4523948842392, 293.5099920746692),\n",
    "(148.8300018310547, 293.5099920746692)],\n",
    "'/page/0/Char/328': [(147.70534186759582, 288.2620484104989),\n",
    "(157.4523948842392, 288.2620484104989),\n",
    "(157.4523948842392, 293.5099920746692),\n",
    "(147.70534186759582, 293.5099920746692)],\n",
    "'/page/0/Char/329': [(155.95284826629407, 288.2620484104989),\n",
    "(165.32501462845116, 288.2620484104989),\n",
    "(165.32501462845116, 293.8848451935385),\n",
    "(155.95284826629407, 293.8848451935385)],\n",
    "'/page/0/Char/330': [(154.82818830283523, 288.2620484104989),\n",
    "(166.07478793742374, 288.2620484104989),\n",
    "(166.07478793742374, 293.5099920746692),\n",
    "(154.82818830283523, 293.5099920746692)],\n",
    "'/page/0/Char/331': [(154.45330164834894, 288.2620484104989),\n",
    "(160.82637477461577, 288.2620484104989),\n",
    "(160.82637477461577, 293.5099920746692),\n",
    "(154.45330164834894, 293.5099920746692)],\n",
    "'/page/0/Char/332': [(155.20307495732152, 288.2620484104989),\n",
    "(163.07569470153348, 288.2620484104989),\n",
    "(163.07569470153348, 293.1351389557999),\n",
    "(155.20307495732152, 293.1351389557999)],\n",
    "'/page/0/Char/333': [(156.32773492078036, 288.2620484104989),\n",
    "(166.07478793742374, 288.2620484104989),\n",
    "(166.07478793742374, 293.5099920746692),\n",
    "(156.32773492078036, 293.5099920746692)],\n",
    "'/page/0/Char/334': [(159.32682815667062, 288.2620484104989),\n",
    "(164.5752413194786, 288.2620484104989),\n",
    "(164.5752413194786, 293.5099920746692),\n",
    "(159.32682815667062, 293.5099920746692)],\n",
    "'/page/0/Char/335': [(160.0766014656432, 288.2620484104989),\n",
    "(164.5752413194786, 288.2620484104989),\n",
    "(164.5752413194786, 293.5099920746692),\n",
    "(160.0766014656432, 293.5099920746692)],\n",
    "'/page/0/Char/336': [(160.0766014656432, 288.2620484104989),\n",
    "(169.44876782780028, 288.2620484104989),\n",
    "(169.44876782780028, 293.5099920746692),\n",
    "(160.0766014656432, 293.5099920746692)],\n",
    "'/page/0/Char/337': [(164.9501279739649, 287.88719529162955),\n",
    "(169.82365448228657, 287.88719529162955),\n",
    "(169.82365448228657, 293.5099920746692),\n",
    "(164.9501279739649, 293.5099920746692)],\n",
    "'/page/0/Char/338': [(167.1994479008826, 288.2620484104989),\n",
    "(175.44695429958082, 287.88719529162955),\n",
    "(175.44695429958082, 293.5099920746692),\n",
    "(167.1994479008826, 293.5099920746692)],\n",
    "'/page/0/Char/339': [(168.32410786434144, 288.2620484104989),\n",
    "(177.69627422649853, 288.2620484104989),\n",
    "(177.69627422649853, 293.5099920746692),\n",
    "(168.32410786434144, 293.5099920746692)],\n",
    "'/page/0/Char/340': [(171.3232011002317, 288.2620484104989),\n",
    "(179.57070749892995, 288.2620484104989),\n",
    "(179.57070749892995, 293.5099920746692),\n",
    "(171.3232011002317, 293.5099920746692)],\n",
    "'/page/0/Char/341': [(176.1967276085534, 288.2620484104989),\n",
    "(181.07025411687508, 288.2620484104989),\n",
    "(181.07025411687508, 293.5099920746692),\n",
    "(176.1967276085534, 293.5099920746692)],\n",
    "'/page/0/Char/342': [(177.69627422649853, 288.2620484104989),\n",
    "(183.31957404379278, 288.2620484104989),\n",
    "(183.31957404379278, 293.8848451935385),\n",
    "(177.69627422649853, 293.8848451935385)],\n",
    "'/page/0/Char/343': [(181.44514077136137, 288.2620484104989),\n",
    "(187.06844058865562, 288.2620484104989),\n",
    "(187.06844058865562, 293.5099920746692),\n",
    "(181.44514077136137, 293.5099920746692)],\n",
    "'/page/0/Char/344': [(182.56980073482023, 288.2620484104989),\n",
    "(187.8182138976282, 288.2620484104989),\n",
    "(187.8182138976282, 293.5099920746692),\n",
    "(182.56980073482023, 293.5099920746692)],\n",
    "'/page/0/Char/345': [(179.19582084444366, 288.2620484104989),\n",
    "(187.8182138976282, 288.2620484104989),\n",
    "(187.8182138976282, 293.5099920746692),\n",
    "(179.19582084444366, 293.5099920746692)],\n",
    "'/page/0/Char/346': [(181.44514077136137, 288.2620484104989),\n",
    "(189.69264717005962, 288.2620484104989),\n",
    "(189.69264717005962, 293.5099920746692),\n",
    "(181.44514077136137, 293.5099920746692)],\n",
    "'/page/0/Char/347': [(182.56980073482023, 288.2620484104989),\n",
    "(190.4424204790322, 288.2620484104989),\n",
    "(190.4424204790322, 293.5099920746692),\n",
    "(182.56980073482023, 293.5099920746692)],\n",
    "'/page/0/Char/348': [(179.94559415341624, 288.2620484104989),\n",
    "(188.94287386108707, 288.2620484104989),\n",
    "(188.94287386108707, 293.5099920746692),\n",
    "(179.94559415341624, 293.5099920746692)],\n",
    "'/page/0/Char/349': [(182.56980073482023, 288.2620484104989),\n",
    "(188.1931005521145, 288.2620484104989),\n",
    "(188.1931005521145, 293.5099920746692),\n",
    "(182.56980073482023, 293.5099920746692)],\n",
    "'/page/0/Char/350': [(186.69355393416936, 288.2620484104989),\n",
    "(197.1903802597853, 288.2620484104989),\n",
    "(197.1903802597853, 293.5099920746692),\n",
    "(186.69355393416936, 293.5099920746692)],\n",
    "'/page/0/Char/351': [(184.06934735276536, 288.2620484104989),\n",
    "(192.6917404059499, 288.2620484104989),\n",
    "(192.6917404059499, 293.5099920746692),\n",
    "(184.06934735276536, 293.5099920746692)],\n",
    "'/page/0/Char/352': [(185.94378062519678, 288.2620484104989),\n",
    "(195.31594698735387, 288.2620484104989),\n",
    "(195.31594698735387, 293.5099920746692),\n",
    "(185.94378062519678, 293.5099920746692)],\n",
    "'/page/0/Char/353': [(192.3168537514636, 288.2620484104989),\n",
    "(202.063906768107, 288.2620484104989),\n",
    "(202.063906768107, 293.5099920746692),\n",
    "(192.3168537514636, 293.5099920746692)],\n",
    "'/page/0/Char/354': [(197.94015356875786, 288.2620484104989),\n",
    "(208.06209323988753, 288.2620484104989),\n",
    "(208.06209323988753, 293.5099920746692),\n",
    "(197.94015356875786, 293.5099920746692)],\n",
    "'/page/0/Char/355': [(199.0648135322167, 288.2620484104989),\n",
    "(206.5625466219424, 288.2620484104989),\n",
    "(206.5625466219424, 293.5099920746692),\n",
    "(199.0648135322167, 293.5099920746692)],\n",
    "'/page/0/Char/356': [(200.93924680464812, 288.2620484104989),\n",
    "(206.93743327642866, 288.2620484104989),\n",
    "(206.93743327642866, 293.5099920746692),\n",
    "(200.93924680464812, 293.5099920746692)],\n",
    "'/page/0/Char/357': [(201.3141334591344, 288.2620484104989),\n",
    "(208.81186654886008, 288.2620484104989),\n",
    "(208.81186654886008, 293.5099920746692),\n",
    "(201.3141334591344, 293.5099920746692)],\n",
    "'/page/0/Char/358': [(198.31504022324415, 288.2620484104989),\n",
    "(208.06209323988753, 288.2620484104989),\n",
    "(208.06209323988753, 293.5099920746692),\n",
    "(198.31504022324415, 293.5099920746692)],\n",
    "'/page/0/Char/359': [(190.81730713351848, 288.2620484104989),\n",
    "(200.56436015016186, 288.2620484104989),\n",
    "(200.56436015016186, 293.5099920746692),\n",
    "(190.81730713351848, 293.5099920746692)],\n",
    "'/page/0/Char/360': [(186.69355393416936, 288.2620484104989),\n",
    "(193.44151371492245, 288.2620484104989),\n",
    "(193.44151371492245, 293.5099920746692),\n",
    "(186.69355393416936, 293.5099920746692)],\n",
    "'/page/0/Char/361': [(179.57070749892995, 288.2620484104989),\n",
    "(188.56798720660078, 288.2620484104989),\n",
    "(188.56798720660078, 293.5099920746692),\n",
    "(179.57070749892995, 293.5099920746692)],\n",
    "'/page/0/Char/362': [(191.94196709697732, 288.2620484104989),\n",
    "(202.063906768107, 288.2620484104989),\n",
    "(202.063906768107, 293.5099920746692),\n",
    "(191.94196709697732, 293.5099920746692)],\n",
    "'/page/0/Char/363': [(175.8218409540671, 288.2620484104989),\n",
    "(188.1931005521145, 288.2620484104989),\n",
    "(188.1931005521145, 293.5099920746692),\n",
    "(175.8218409540671, 293.5099920746692)],\n",
    "'/page/0/Char/364': [(174.69718099060827, 288.2620484104989),\n",
    "(185.1940073162242, 288.2620484104989),\n",
    "(185.1940073162242, 293.1351389557999),\n",
    "(174.69718099060827, 293.1351389557999)],\n",
    "'/page/0/Char/365': [(173.19763437266312, 288.2620484104989),\n",
    "(186.69355393416936, 288.2620484104989),\n",
    "(186.69355393416936, 293.1351389557999),\n",
    "(173.19763437266312, 293.1351389557999)],\n",
    "'/page/0/Char/366': [(171.698087754718, 288.2620484104989),\n",
    "(184.81912066173794, 288.2620484104989),\n",
    "(184.81912066173794, 293.1351389557999),\n",
    "(171.698087754718, 293.1351389557999)],\n",
    "'/page/0/Char/367': [(176.94650091752598, 288.2620484104989),\n",
    "(192.3168537514636, 288.2620484104989),\n",
    "(192.3168537514636, 293.1351389557999),\n",
    "(176.94650091752598, 293.1351389557999)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)\n",
    "min([v[0][0] for k,v in a.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescaling boxes\n",
    "\n",
    "import copy\n",
    "def rescale_chars_to_line(boxlist):\n",
    "    \"\"\"\n",
    "    Rescales all char bboxes inside one line so they fit into the line bbox.\n",
    "    \n",
    "    Args:\n",
    "        line_dict (dict): JSON for a line (with bbox + Char children).\n",
    "    Returns:\n",
    "        dict: updated line_dict with corrected char bboxes.\n",
    "    \"\"\"\n",
    "    boxes = copy.deepcopy(boxlist)\n",
    "\n",
    "    lx0, ly0, lx1, ly1 = (59.981864717805415,\n",
    "                              287.13748905389093,\n",
    "                              278.1658976288226,\n",
    "                              295.38425766901577)\n",
    "    line_width = lx1 - lx0\n",
    "    line_height = ly1 - ly0\n",
    "\n",
    "    # OCR min/max from chars\n",
    "    cx0 = min([v[0][0] for k,v in boxes.items()])\n",
    "    cy0 = min([v[0][1] for k,v in boxes.items()])\n",
    "    cx1 = max([v[2][0] for k,v in boxes.items()])\n",
    "    cy1 = max([v[2][1] for k,v in boxes.items()])\n",
    "    print(cx0,cy0,cx1,cy1)\n",
    "\n",
    "    ocr_width = cx1 - cx0\n",
    "    ocr_height = cy1 - cy0\n",
    "\n",
    "    def transform_coords(coords):\n",
    "        x0,y0,x1,y1 = (coords[0][0],coords[0][1],coords[2][0],coords[2][1])\n",
    "\n",
    "        x0 = x0 * ocr_width / line_width\n",
    "        y0 = y0 * ocr_height / line_height\n",
    "        x1 = x1 * ocr_width / line_width\n",
    "        y1 = y0 * ocr_height / line_height\n",
    "        return [(x0,y0),(x0,y1),(x1,y1),(x1,y0)]\n",
    "\n",
    "    for k,val in boxes.items():\n",
    "    \n",
    "        boxes.update({k:transform_coords(val)})\n",
    "     \n",
    "    return boxes\n",
    "\n",
    "a = rescale_chars_to_line(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a['/page/0/Char/311'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = renderedboxes[0][0]\n",
    "c = renderedtext[0][0]\n",
    "# print(c)\n",
    "\n",
    "blanks = []\n",
    "\n",
    "for rchar, rcoord in zip(c.items(),b.items()):\n",
    "    if rchar[1] == ' ' and re.match('^/page/0/Char/(3[0-5][0-9]|36[0-7])$',rchar[0]):\n",
    "        blanks.append(rcoord[1])\n",
    "\n",
    "print(blanks)\n",
    "\n",
    "import copy\n",
    "def rescale_chars_to_line(boxlist,k):\n",
    "\n",
    "    boxes = []\n",
    "\n",
    "    lx0, ly0, lx1, ly1 = (59.981864717805415,\n",
    "                              287.13748905389093,\n",
    "                              278.1658976288226,\n",
    "                              295.38425766901577)\n",
    "\n",
    "    lmidx = (lx1+lx0)/2\n",
    "\n",
    "    def transform_coords(coords,k):\n",
    "        x0,x1 = (coords[0][0],coords[2][0])\n",
    "        x_new = (x0+x1)/2\n",
    "        x_new = x_new - k * (lmidx - x_new)\n",
    "        return [(x_new,ly0),(x_new,ly1),(x_new,ly1),(x_new,ly0)]\n",
    "\n",
    "    for box in boxlist:\n",
    "    \n",
    "        boxes.append(transform_coords(box,k))\n",
    "     \n",
    "    return boxes\n",
    "\n",
    "blanks = rescale_chars_to_line(blanks,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_doc(filename,filedir):\n",
    "\n",
    "\n",
    "\n",
    "    init_file = filedir + filename + \".pdf\"\n",
    "    doc = pymupdf.open(init_file)\n",
    "    page = doc[0]\n",
    "    for annot in page.annots():\n",
    "        page.delete_annot(annot)\n",
    "    doc.saveIncr()\n",
    "    doc.close()\n",
    "    page=None\n",
    "\n",
    "clear_doc(\"page1test\",\"./docs_to_write_on/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redact specific coordinates\n",
    "\n",
    "# def redact_pdf(filename,filedir, coords):\n",
    "#     init_file = filedir + filename + \".pdf\"\n",
    "#     doc = fitz.open(init_file)\n",
    "#     for page in doc:\n",
    "#         print(page.rect.width,page.rect.height)\n",
    "#         page.add_redact_annot(coords, fill=(0, 0, 0))\n",
    "#     doc.save(\"output1.pdf\")\n",
    "#     doc.close()\n",
    "\n",
    "\n",
    "def annotate_specific_coords(filename,filedir,coords,colour):\n",
    "    init_file = filedir + filename + \".pdf\"\n",
    "    doc = pymupdf.open(init_file)\n",
    "    page = doc[0]\n",
    "    annot = page.add_polygon_annot(coords)\n",
    "    annot.set_colors(stroke=colour)\n",
    "    annot.update()\n",
    "    doc.saveIncr()\n",
    "    doc.close()\n",
    "    page=None\n",
    "\n",
    "\n",
    "for spacetem in blanks:\n",
    "    specific_annot =  spacetem\n",
    "    paint = (0,0,1)\n",
    "    # (0.416, 0.416, 1)\n",
    "\n",
    "    annotate_specific_coords(\"page1test\",\"./docs_to_write_on/\",specific_annot,paint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lx0,ly0,lx1,ly1 = (59.981864717805415,\n",
    "                              287.13748905389093,\n",
    "                              278.1658976288226,\n",
    "                              295.38425766901577)\n",
    "\n",
    "lmidx = (lx1+lx0)/2\n",
    "\n",
    "\n",
    "\n",
    "lmidpoint = [(lmidx,ly0),(lmidx,ly0),(lmidx,ly1),(lmidx,ly1)]\n",
    "\n",
    "\n",
    "\n",
    "paint = (0,0,0)\n",
    "annotate_specific_coords(\"page1test\",\"./docs_to_write_on/\",lmidpoint,paint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plan B: Eyeball it\n",
    "clear_doc(\"page1test\",\"./docs_to_write_on/\")\n",
    "lx0,ly0,lx1,ly1 = (59.981864717805415,\n",
    "                              287.13748905389093,\n",
    "                              278.1658976288226,\n",
    "                              295.38425766901577)\n",
    "\n",
    "htmtext = 'We propose the use of dilated filters to construct an ag-\\n'\n",
    "\n",
    "cleantext = re.sub('[\\r\\n]+',\"\",htmtext)\n",
    "\n",
    "\n",
    "\n",
    "def cut_up_line(tex):\n",
    "    \n",
    "    lx0,ly0,lx1,ly1 = (59.981864717805415,\n",
    "                              287.13748905389093,\n",
    "                              278.1658976288226,\n",
    "                              295.38425766901577)\n",
    "    \n",
    "\n",
    "    leng = lx1-lx0\n",
    "\n",
    "    lengcut = leng / len(tex) * 1.5\n",
    "\n",
    "    cutboxes = np.arange(lx0,lx1,lengcut).tolist() + [lx1]\n",
    "    return [[(cutboxes[j],ly0),(cutboxes[j+1],ly0),(cutboxes[j+1],ly1),(cutboxes[j],ly1)] for j,x in enumerate(cutboxes) if j < len(cutboxes)-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cuts = cut_up_line(cleantext)\n",
    "\n",
    "def annotate_specific_coords(filename,filedir,coords,colour):\n",
    "    init_file = filedir + filename + \".pdf\"\n",
    "    doc = pymupdf.open(init_file)\n",
    "    page = doc[0]\n",
    "    annot = page.add_polygon_annot(coords)\n",
    "    annot.set_colors(stroke=colour)\n",
    "    annot.update()\n",
    "    doc.saveIncr()\n",
    "    doc.close()\n",
    "    page=None\n",
    "\n",
    "\n",
    "for gaps in cuts:\n",
    "    specific_annot = gaps\n",
    "    paint = (0,0,1)\n",
    "    # (0.416, 0.416, 1)\n",
    "\n",
    "    annotate_specific_coords(\"page1test\",\"./docs_to_write_on/\",specific_annot,paint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quickly turn PDF to images\n",
    "\n",
    "pages = convert_from_path(current_file)\n",
    "for count, page in enumerate(pages):\n",
    "    page.save(f'out{count}.jpg', 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF/Image pre-processing to improve Tesseract results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# img = Image.open(\"./testactual_page-0001.jpg\")\n",
    "# print(img)\n",
    "# osd = pyt.image_to_osd(img,output_type=\"dict\")\n",
    "# print(osd)\n",
    "\n",
    "\n",
    "img = cv2.imread(\"./out0.jpg\")\n",
    "img = cv2.resize(img,(0,0),fx=7,fy=7)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "invert = 255 - opening\n",
    "\n",
    "# im = img.filter(ImageFilter.MedianFilter())\n",
    "# enhancer = ImageEnhance.Contrast(im)\n",
    "# im = enhancer.enhance(2)\n",
    "# im = im.convert('1')\n",
    "# im.save('temp2.jpg')\n",
    "\n",
    "osd = pyt.image_to_osd(invert,output_type=\"dict\")\n",
    "print(osd)\n",
    "\n",
    "# cv2.imshow('thresh', thresh)\n",
    "# cv2.imshow('opening', opening)\n",
    "# cv2.imshow('invert', invert)\n",
    "# cv2.waitKey()\n",
    "\n",
    "page_text = pyt.image_to_string(invert, lang=\"Greek\",config=\"--psm 1 -c tessedit_ocr_engine_mode=1\")\n",
    "print(f\"OCR result for page 1: {page_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break PDF into one file per page (for troubleshooting marker)\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "\n",
    "goesin = \"base_test.pdf\"\n",
    "comesout = \"split_pdf\"\n",
    "\n",
    "def split_pdf(input_pdf, output_dir):\n",
    "    # Open the source PDF\n",
    "    doc = fitz.open(input_pdf)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over all pages\n",
    "    for page_num in range(len(doc)):\n",
    "        # Create a new PDF for each page\n",
    "        new_doc = fitz.open()\n",
    "        new_doc.insert_pdf(doc, from_page=page_num, to_page=page_num)\n",
    "\n",
    "        # Save with page number in filename (1-indexed for readability)\n",
    "        output_path = os.path.join(output_dir, f\"page_{page_num+1}.pdf\")\n",
    "        new_doc.save(output_path)\n",
    "        new_doc.close()\n",
    "\n",
    "        print(f\"Saved {output_path}\")\n",
    "\n",
    "    doc.close()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "split_pdf(goesin, comesout)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
