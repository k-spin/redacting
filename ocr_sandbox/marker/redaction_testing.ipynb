{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pdfplumber\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# import pytesseract as pyt\n",
    "import fitz\n",
    "import pymupdf\n",
    "# from pdf2image import convert_from_path\n",
    "# from PIL import Image, ImageEnhance, ImageFilter\n",
    "# import cv2\n",
    "# from tesserocr import PyTessBaseAPI, RIL\n",
    "# import tesserocr\n",
    "import json\n",
    "import pprint\n",
    "import re\n",
    "from dotenv import find_dotenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# marker functions\n",
    "from marker.converters.ocr import OCRConverter\n",
    "from marker.converters.pdf import PdfConverter\n",
    "from marker.models import create_model_dict\n",
    "from marker.config.parser import ConfigParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile = \"page1-cli-ocr-force-strip-chars\"\n",
    "directory = \"/content/testing/\" + testfile + \".pdf\"\n",
    "\n",
    "config = {\n",
    "    \"output_format\": \"json\",\n",
    "    \"OCRJSONRenderer_extract_images\": \"True\",\n",
    "    \"disable_image_extraction\": \"True\",\n",
    "    \"DEBUG\":\"True\",\n",
    "    \"force_ocr\":\"True\",\n",
    "    \"strip_existing_ocr\": \"True\"\n",
    "}\n",
    "config_parser = ConfigParser(config)\n",
    "converter = OCRConverter(\n",
    "    config=config_parser.generate_config_dict(),\n",
    "    artifact_dict=create_model_dict(),\n",
    ")\n",
    "rendered = converter(directory)\n",
    "\n",
    "output_filename = \"/content/testing/\" + \"marker-\" + testfile + \".json\"\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(rendered.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if individual file is repaired (before uploading to marker-pdf)\n",
    "# quickcheckname = \"textract_test\"\n",
    "# doc = pymupdf.open(\"./docs_to_write_on/\"+ quickcheckname + \".pdf\")\n",
    "# print(doc.can_save_incrementally())\n",
    "# doc.close()\n",
    "# page=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marker testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file-list to process\n",
    "\n",
    "pdfolder = \"./docs_to_write_on/\"\n",
    "jsonfolder = \"./jsons_to_read/\"\n",
    "nameslist = set([filename[:-4] for filename in os.listdir(pdfolder)])   # read all files in directory and cut off extensions (keep file names only), set-type object for faster comparison later\n",
    "print(nameslist)\n",
    "\n",
    "# use this portion to opt in/out files to be run later\n",
    "\n",
    "opt_out = {'page1test'}\n",
    "nameslist = [name for name in nameslist if name not in opt_out]\n",
    "print(nameslist)\n",
    "\n",
    "#replace cutting off 'marker-' with regex\n",
    "verificationset = set([filename[7:] for filename in [filename[:-5] for filename in os.listdir(jsonfolder)]]).symmetric_difference(nameslist)   # cut off marker- prefix and .json extension from json files and compare to namelist sets to verify no issues\n",
    "if verificationset == opt_out:\n",
    "    verificationset = set()\n",
    "print(verificationset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify files before uploading to marker or opening with PyMuPDF\n",
    "\n",
    "def check_ok_for_marker(filename, filedir):\n",
    "    \n",
    "    init_file = filedir + filename + \".pdf\"\n",
    "    doc = pymupdf.open(init_file)\n",
    "\n",
    "    if not doc.can_save_incrementally():\n",
    "\n",
    "        print(f'File: \"{filename}\" unwritable. Fixing...')\n",
    "\n",
    "        new_file = filedir + filename + \"-fixed\" + \".pdf\"\n",
    "        doc.save(new_file, garbage=4,deflate=True)\n",
    "        doc.close()\n",
    "        page=None\n",
    "        os.remove(init_file)\n",
    "        os.rename(new_file,init_file)\n",
    "    else:\n",
    "        print('Nothing to fix!')\n",
    "\n",
    "if len(verificationset)==0 :   # change this to check only files that are outside the verificationlist\n",
    "    for pdf_file in nameslist:\n",
    "        check_ok_for_marker(pdf_file,pdfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renderedlist = []\n",
    "for json_file in nameslist:\n",
    "    with open(jsonfolder + \"marker-\" + json_file + \".json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        renderedlist.append(json.load(f)['children'])\n",
    "\n",
    "for json_file in renderedlist:\n",
    "  pprint.pprint(json_file, indent=2)\n",
    "# print(renderedlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve specific defined coordinates from JSON, \"flatten\" data\n",
    "\n",
    "# Marker-defined categories (specifically leaves only) to extract from marker output JSON. Parse through the output JSON to find new leaf categories to add for extraction\n",
    "leaf_categories_with_text = ['Line','Text','TextInlineMath','Caption','ListItem','SectionHeader','TableCell', 'PageFooter','PageHeader']\n",
    "leaf_categories_to_retrieve = ['Picture','TableGroup','Equation', 'Figure', 'Handwriting']\n",
    "\n",
    "# For data retrieved from parsing with the full marker PDF model. Recursive function to retrieve all coordinates and text of identified objects\n",
    "def retrieve_specific_boxes_and_flatten(treelist,pull_polygons,pull_text):\n",
    "  # recursive function to pick up all the coordinates, and all HTML text from specifically defined configurations of nested items\n",
    "  coordinates = {}\n",
    "  htmtext = {}\n",
    "  \n",
    "  for nitem,item in enumerate(treelist):\n",
    "    newpoly = {}\n",
    "    newtext = {}\n",
    "    if (item['children']):\n",
    "      # newpoly = {'size':[tuple(point) for point in item['polygon']]}\n",
    "      newchildren = item['children']\n",
    "      retr_coords,retr_text = retrieve_specific_boxes_and_flatten(newchildren,pull_polygons,pull_text)\n",
    "      newpoly.update(retr_coords)\n",
    "      newtext.update(retr_text)\n",
    "      if item['block_type']=='Page':\n",
    "        newitem_poly = {int(re.search(r\"/page/(\\d+)/\", item['id']).group(1)):newpoly}\n",
    "        newitem_text = {int(re.search(r\"/page/(\\d+)/\", item['id']).group(1)):newtext}\n",
    "      else: \n",
    "        newitem_poly = newpoly\n",
    "        newitem_text = newtext\n",
    "    else:\n",
    "      if (item['block_type'] in pull_polygons) or (item['block_type'] in pull_text) :\n",
    "        newpoly = item['polygon']\n",
    "        newpoly = [tuple(point) for point in newpoly]\n",
    "        newitem_poly = {item['id']:newpoly}\n",
    "        if item['block_type'] in pull_text:\n",
    "          newtext = item['html']\n",
    "          newitem_text = {item['id']:newtext}\n",
    "        else:\n",
    "          newitem_text = {}\n",
    "      else: \n",
    "        newitem_poly = {}\n",
    "        newitem_text = {}\n",
    "    coordinates.update(newitem_poly)\n",
    "    htmtext.update(newitem_text)\n",
    "  return (coordinates,htmtext)\n",
    "\n",
    "# For data retrieved from parsing with the OCR-ONLY marker PDF model with the --keep-chars flag active. Recursive function to retrieve all coordinates and \n",
    "# text of identified objects. The difference from the full model function are the 'Char' objects. They do not have a 'children' attribute and the retrieval throws an error\n",
    "# (could technically only use this function but I like to have them differentiated)\n",
    "def ocr_retrieve_specific_boxes_and_flatten(treelist,pull_polygons,pull_text):\n",
    "  # recursive function to pick up all the coordinates from specifically defined configurations of nested items\n",
    "  coordinates = {}\n",
    "  htmtext = {}\n",
    "  \n",
    "  for nitem,item in enumerate(treelist):\n",
    "    newpoly = {}\n",
    "    newtext = {}\n",
    "    if (item['block_type'] == 'Char'):\n",
    "        newpoly = item['polygon']\n",
    "        newpoly = [tuple(point) for point in newpoly]\n",
    "        newitem_poly = {item['id']:newpoly}\n",
    "        newtext = item['text']\n",
    "        newitem_text = {item['id']:newtext}\n",
    "    else:\n",
    "        if (item['children']):\n",
    "            # newpoly = {'size':[tuple(point) for point in item['polygon']]}\n",
    "            newchildren = item['children']\n",
    "            retr_coords,retr_text = ocr_retrieve_specific_boxes_and_flatten(newchildren,pull_polygons,pull_text)\n",
    "            newpoly.update(retr_coords)\n",
    "            newtext.update(retr_text)\n",
    "            if item['block_type']=='Page':\n",
    "                newitem_poly = {int(re.search(r\"/page/(\\d+)/\", item['id']).group(1)):newpoly}\n",
    "                newitem_text = {int(re.search(r\"/page/(\\d+)/\", item['id']).group(1)):newtext}\n",
    "            else: \n",
    "                newitem_poly = newpoly\n",
    "                newitem_text = newtext\n",
    "        else:\n",
    "            if (item['block_type'] in pull_polygons) or (item['block_type'] in pull_text) :\n",
    "                newpoly = item['polygon']\n",
    "                newpoly = [tuple(point) for point in newpoly]\n",
    "                newitem_poly = {item['id']:newpoly}\n",
    "                if item['block_type'] in pull_text:\n",
    "                    newtext = item['html']\n",
    "                    newitem_text = {item['id']:newtext}\n",
    "                else:\n",
    "                    newitem_text = {}\n",
    "            else: \n",
    "                newitem_poly = {}\n",
    "                newitem_text = {}\n",
    "    coordinates.update(newitem_poly)\n",
    "    htmtext.update(newitem_text)\n",
    "  return (coordinates,htmtext)\n",
    "\n",
    "\n",
    "\n",
    "renderedboxes = []\n",
    "renderedtext = []\n",
    "\n",
    "for name,red_lines in zip(nameslist,renderedlist):\n",
    "  if re.search('(chars)', name):\n",
    "    all_boxes,all_text = ocr_retrieve_specific_boxes_and_flatten(red_lines,leaf_categories_to_retrieve,leaf_categories_with_text)\n",
    "  else:\n",
    "    all_boxes,all_text = retrieve_specific_boxes_and_flatten(red_lines,leaf_categories_to_retrieve,leaf_categories_with_text)\n",
    "\n",
    "\n",
    "  renderedboxes.append(all_boxes)\n",
    "  renderedtext.append(all_text) \n",
    "\n",
    "for boxes,texts in zip(renderedboxes,renderedtext):\n",
    "   display(boxes)\n",
    "   display(texts)\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "\n",
    "# old JSON processing function, workd for simple OCR model, fails for Full model\n",
    "\n",
    "# def retrieve_all_boxes(treelist):\n",
    "#   # recursive function to pick up all the coordinates from any configuration of nested items\n",
    "#   newdict = {}\n",
    "#   # location = location + \" \" + str(nitem)\n",
    "#   # all_boxes.update({location:item['polygon']})\n",
    "#   for nitem,item in enumerate(treelist):\n",
    "#     if (item['children']):\n",
    "#       newpoly = {'size':[tuple(point) for point in item['polygon']]}\n",
    "#       newchildren = item['children']\n",
    "#       newpoly.update(retrieve_all_boxes(newchildren))\n",
    "#       if item['block_type']=='Page':\n",
    "#         newid = int(re.search(r\"/page/(\\d+)/\", item['id']).group(1))\n",
    "#       else: newid = item['id']\n",
    "#     else:\n",
    "#       newpoly = item['polygon']\n",
    "#       newpoly = [tuple(point) for point in newpoly]\n",
    "#       newid = item['id']\n",
    "   \n",
    "#     newdict.update({newid:newpoly})\n",
    "#   return newdict\n",
    "\n",
    "# all_boxes = retrieve_all_boxes(red_lines)\n",
    "# display(all_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write coordinate boxes to PDF\n",
    "\n",
    "\n",
    "def add_boxes(filename, filedir, annotations):\n",
    "\n",
    "  # open current document\n",
    "  init_file = filedir + filename + \".pdf\"\n",
    "  doc = pymupdf.open(init_file)\n",
    "\n",
    "  # check file health and save as new file (fixes marker-pdf PIL errors and PyMuPDF 'code=4' errors)\n",
    "  if not doc.can_save_incrementally():\n",
    "    print(f'File: \"{filename}\" unwritable. Fixing...')\n",
    "    # filename = filename + \"-fixed\"\n",
    "    new_file = filedir + filename + \"-fixed\" + \".pdf\"\n",
    "    doc.save(new_file, garbage=4,deflate=True)\n",
    "    doc.close()\n",
    "    page=None\n",
    "    os.remove(init_file)\n",
    "    os.rename(new_file,init_file)\n",
    "    doc = pymupdf.open(init_file)\n",
    "  \n",
    "  for i,page in enumerate(doc):\n",
    "    lines = annotations[i]\n",
    "    nannots = len(lines)\n",
    "    for ncoord,coords in enumerate(lines.items()):\n",
    "      print(f\"Page {i}: Adding annotation {ncoord} / {nannots}\",end='\\r')\n",
    "      annot = page.add_polygon_annot(coords[1])\n",
    "      annot.set_colors(stroke=(0.416, 0.416, 1))\n",
    "      annot.update()\n",
    "      doc.saveIncr()\n",
    "  doc.close()\n",
    "  page=None\n",
    "  print(f'\"{filename}\" annotated.')\n",
    "\n",
    "\n",
    "def print_retrieved_text(texttoprint):\n",
    "  for item in texttoprint.values():\n",
    "    for textblock in item.values():\n",
    "      print(re.sub( \"<(\\w+)([\\s\\-\\w='\\\":/\\.]+)?>\" ,\"\",re.sub( \"<(/\\w+)([\\s\\w=':/\\.]+)?>\" ,\"\",textblock)))\n",
    "\n",
    "for name,boxes,texts in zip(nameslist,renderedboxes,renderedtext):\n",
    "  add_boxes(name, pdfolder, boxes)\n",
    "  print_retrieved_text(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kofax: Pulling signatures from processed PDF \n",
    "(using Kofax, transform to Word and then back to PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, fitz, unicodedata\n",
    "\n",
    "# ---- helpers ---- \n",
    "def norm(s):\n",
    "    s = unicodedata.normalize('NFKC', str(s))\n",
    "    return s.replace('\\u00B7','.')  # middle dot → '.'\n",
    "\n",
    "# τίτλοι που ενεργοποιούν Wipe-Βand\n",
    "HEAD_TRIGGERS = [\n",
    "  'ΟΙ ΣΥΜΒΑΛΛΟΜΕΝΟΙ', 'Ο ΣΥΜΒΑΛΛΟΜΕΝΟΣ', 'Η ΣΥΜΒΑΛΛΟΜΕΝΗ',\n",
    "  'Ο ΣΥΝΕΤΑΙΡΟΣ ΠΙΣΤΟΥΧΟΣ', 'ΟΙ ΣΥΝΟΦΕΙΛΕΤΗΣ', 'Ο/ΟΙ ΣΥΝΟΦΕΙΛΕΤΗΣ/ΕΣ',\n",
    "  'Ο/ΟΙ ΕΓΓΥΗΤΗΣ/ΕΣ', 'Ο ΕΓΓΥΗΤΗΣ', 'Ο ΟΦΕΙΛΕΤΗΣ', 'Ο/ΟΙ ΟΦΕΙΛΕΤΗΣ/ΕΣ'\n",
    "]\n",
    "\n",
    "def text_blocks(page):\n",
    "    # rawdict → blocks (text/images) με bbox\n",
    "    data = page.get_text('rawdict')\n",
    "    return data.get('blocks', []) if isinstance(data, dict) else []\n",
    "\n",
    "def find_heading_band(page, side_margin=10, top_offset=6):\n",
    "    # ψάξε αν υπάρχει τίτλος-κλειδί στη σελίδα και γύρνα ζώνη (x0,y0,x1,y1)\n",
    "    W,H = page.rect.width, page.rect.height\n",
    "    best_y = None\n",
    "    for b in text_blocks(page):\n",
    "        if b.get('type') != 0: continue  # μόνο text blocks\n",
    "        for l in b.get('lines', []):\n",
    "            line_text = ' '.join([s.get('text','') for s in l.get('spans',[])])\n",
    "            T = norm(line_text).upper().strip()\n",
    "            for key in HEAD_TRIGGERS:\n",
    "                if key in T:\n",
    "                    # πάρε bbox της γραμμής\n",
    "                    xs=[]; ys=[]\n",
    "                    for s in l.get('spans', []):\n",
    "                        (x0,y0,x1,y1) = s.get('bbox', (None,None,None,None))\n",
    "                        if x0 is None: continue\n",
    "                        xs += [x0,x1]; ys += [y0,y1]\n",
    "                    if xs and ys:\n",
    "                        y_line = max(ys)  # κάτω άκρη γραμμής\n",
    "                        best_y = y_line if best_y is None else min(best_y, y_line)\n",
    "    if best_y is None: return None\n",
    "    x0 = page.rect.x0 + side_margin\n",
    "    y0 = best_y + top_offset\n",
    "    x1 = page.rect.x1 - side_margin\n",
    "    y1 = page.rect.y1 - 8\n",
    "    return (x0,y0,x1,y1) if y0 < y1 else None\n",
    "\n",
    "def image_boxes_in_band(page, band=None, bottom_ratio=0.35):\n",
    "    boxes = []\n",
    "    W,H = page.rect.width, page.rect.height\n",
    "    bottom_y = H*(1.0-bottom_ratio)\n",
    "    for b in text_blocks(page):\n",
    "        if b.get('type') == 1:  # image\n",
    "            (x0,y0,x1,y1) = b.get('bbox', (None,None,None,None))\n",
    "            if x0 is None: continue\n",
    "            # κριτήρια: (i) τέμνει band ή (ii) βρίσκεται στο κάτω Χ% της σελίδας\n",
    "            in_bottom = (y0 >= bottom_y) or (y1 >= bottom_y)\n",
    "            intersects_band = False\n",
    "            if band is not None:\n",
    "                bx0,by0,bx1,by1 = band\n",
    "                intersects_band = not (x1<bx0 or x0>bx1 or y1<by0 or y0>by1)\n",
    "            if intersects_band or in_bottom:\n",
    "                boxes.append((x0,y0,x1,y1))\n",
    "    return boxes\n",
    "\n",
    "def redact_pdf(input_pdf, output_pdf, do_wipe=True, do_images=True, side_margin=10, top_offset=6, bottom_ratio=0.35, fill='white', draw_labels=False):\n",
    "    rgb=(1,1,1) if str(fill).lower()=='white' else (0,0,0)\n",
    "    doc = fitz.open(input_pdf)\n",
    "    for pno in range(len(doc)):\n",
    "        page = doc[pno]\n",
    "        band = find_heading_band(page, side_margin=side_margin, top_offset=top_offset) if do_wipe else None\n",
    "        if band:\n",
    "            r = fitz.Rect(band)\n",
    "            page.add_redact_annot(r, text=('[SIGN-BAND]' if draw_labels else None), fill=rgb)\n",
    "        if do_images:\n",
    "            for (x0,y0,x1,y1) in image_boxes_in_band(page, band=band, bottom_ratio=bottom_ratio):\n",
    "                r = fitz.Rect(x0,y0,x1,y1)\n",
    "                page.add_redact_annot(r, text=('[IMG]' if draw_labels else None), fill=rgb)\n",
    "        page.apply_redactions()\n",
    "    doc.save(output_pdf, garbage=4, deflate=True)\n",
    "    doc.close()\n",
    "\n",
    "\n",
    "redact_pdf('test_text_and_signaturesdoc.pdf',\"out_signzones.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure: DocumentIntelligence for OCR\n",
    "\n",
    "and integrating an NER model on the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path='./config/.env')\n",
    "\n",
    "AZURE_ENDPOINT = os.getenv('AZURE_ENDPOINT')\n",
    "AZURE_KEY = os.getenv('AZURE_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_CONFIG = {\n",
    "    \"endpoint\" : AZURE_ENDPOINT,\n",
    "    \"key\" : AZURE_KEY\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TesserOCR: Testing library to get coordinates\n",
    "\n",
    "After pre-OCR-ing with Tungsten/Kofax PowerPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Tesseract + output images (i think)\n",
    "\n",
    "# Define Tesseract exe location\n",
    "pyt.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "pyt.get_languages()\n",
    "\n",
    "current_file = \"testtest.pdf\"\n",
    "\n",
    "\n",
    "\n",
    "def ocr_scanned_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    images = convert_from_path(pdf_path)    \n",
    "    for i, image in enumerate(images):\n",
    "        page_text = pyt.image_to_string(image, lang=\"ell\",config=\"--psm 4 --oem 3 -c tessedit_write_images=true\")      \n",
    "        print(f\"OCR result for page {i+1}: {page_text}\")\n",
    "        # text += f\"--- Page {i+1} ---\\n{page_text}\\n\\n\"\n",
    "    return text\n",
    "\n",
    "\n",
    "ocr_scanned_pdf(current_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite initial file to contain all coordinates of identified words\n",
    "\n",
    "\n",
    "insertions = []\n",
    "\n",
    "# open document\n",
    "input_pdf = \"testtest.pdf\"\n",
    "doc = fitz.open(input_pdf)\n",
    "\n",
    "# insert here transform pdf to image\n",
    "images = convert_from_path(input_pdf)\n",
    "print(images)\n",
    "\n",
    "\n",
    "def transform_coords(box):\n",
    "    # assume of dict format with {'x':x,'y':y,'w':w,'h':h}\n",
    "    x1 = box['x']\n",
    "    y1 = box['y']\n",
    "    w = box['w']\n",
    "    h = box['h']\n",
    "    x2 = x1+w\n",
    "    y2 = y1+h\n",
    "\n",
    "    # with polygon annotation:\n",
    "    coordinates_pdf = [(x1*scale_x - 2,y1*scale_y - 2),(x2*scale_x + 2,y1*scale_y - 2), (x2*scale_x + 2,y2*scale_y + 2),(x1*scale_x - 2,y2*scale_y + 2)]\n",
    "\n",
    "    # with redact annotation:\n",
    "\n",
    "\n",
    "    return coordinates_pdf\n",
    "\n",
    "\n",
    "for j,image in enumerate(images):\n",
    "\n",
    "    insertions_temp_dict = {}\n",
    "\n",
    "    with PyTessBaseAPI(path=r'C:\\Program Files\\Tesseract-OCR\\tessdata', lang='ell') as api:\n",
    "\n",
    "\n",
    "        api.SetImage(image)\n",
    "\n",
    "        # get all sizes\n",
    "        currentpage = j\n",
    "        imgsize = image.size\n",
    "        page = doc[currentpage]\n",
    "        scale_x = page.rect.width / imgsize[0]\n",
    "        scale_y = page.rect.height / imgsize[1]\n",
    "\n",
    "        boxes = api.GetComponentImages(RIL.TEXTLINE, True)\n",
    "        total_items = len(boxes)\n",
    "        print('Found {} textline image components.'.format(total_items))\n",
    "        for i, (im, box, _, _) in enumerate(boxes):\n",
    "\n",
    "            api.SetRectangle(box['x'], box['y'], box['w'], box['h'])\n",
    "            ocrResult = api.GetUTF8Text()\n",
    "            conf = api.MeanTextConf()\n",
    "\n",
    "            # create box visually on PDF and add embellishments\n",
    "            pdf_transformed_coordinates = transform_coords(box)\n",
    "            # print(pdf_transformed_coordinates)\n",
    "            print(pdf_transformed_coordinates)\n",
    "            annot = page.add_polygon_annot(pdf_transformed_coordinates)\n",
    "            annot.set_colors(stroke=(0.416, 0.416, 1))\n",
    "            annot.update()\n",
    "\n",
    "            # # add text for visual representation\n",
    "            # text_rect = fitz.Rect(pdf_transformed_coordinates[0][0],pdf_transformed_coordinates[0][1],pdf_transformed_coordinates[2][0],pdf_transformed_coordinates[2][1])\n",
    "            # # text_rect = fitz.Rect(100,100,100,100)\n",
    "            # page.insert_textbox(\n",
    "            #     text_rect,\n",
    "            #     ocrResult,\n",
    "            #     fontsize=3,\n",
    "            #     fontname=\"helv\",\n",
    "            #     color=(0, 0, 0),   # black text\n",
    "            #     align=1            # center align\n",
    "            # )\n",
    "\n",
    "            # insertions_temp_dict.update({i:inserted})\n",
    "            doc.saveIncr()\n",
    "            print(f\"\\rProgress: {i+1}/{total_items}\",\"\\r\",end=\"\")\n",
    "    insertions.append(insertions_temp_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "doc.close()\n",
    "page = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redact specific coordinates\n",
    "\n",
    "def redact_pdf(filename,filedir, coords):\n",
    "    init_file = filedir + filename + \".pdf\"\n",
    "    doc = fitz.open(init_file)\n",
    "    for page in doc:\n",
    "        print(page.rect.width,page.rect.height)\n",
    "        page.add_redact_annot(coords, fill=(0, 0, 0))\n",
    "    doc.save(\"output1.pdf\")\n",
    "    doc.close()\n",
    "\n",
    "\n",
    "def annotate_specific_coords(filename,filedir,coords):\n",
    "    init_file = filedir + filename + \".pdf\"\n",
    "    doc = pymupdf.open(init_file)\n",
    "    page = doc[0]\n",
    "    annot = page.add_polygon_annot(coords)\n",
    "    annot.set_colors(stroke=(0.416, 0.416, 1))\n",
    "    annot.update()\n",
    "    doc.saveIncr()\n",
    "    doc.close()\n",
    "    page=None\n",
    "\n",
    "\n",
    "\n",
    "specific_annot = [ (59.981864717805415, 287.13748905389093),\n",
    "                                 (278.1658976288226, 287.13748905389093),\n",
    "                                 (278.1658976288226, 295.38425766901577),\n",
    "                                 (59.981864717805415, 295.38425766901577)]\n",
    "\n",
    "annotate_specific_coords(\"page1test\",\"./docs_to_write_on/\",specific_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quickly turn PDF to images\n",
    "\n",
    "pages = convert_from_path(current_file)\n",
    "for count, page in enumerate(pages):\n",
    "    page.save(f'out{count}.jpg', 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF/Image pre-processing to improve Tesseract results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# img = Image.open(\"./testactual_page-0001.jpg\")\n",
    "# print(img)\n",
    "# osd = pyt.image_to_osd(img,output_type=\"dict\")\n",
    "# print(osd)\n",
    "\n",
    "\n",
    "img = cv2.imread(\"./out0.jpg\")\n",
    "img = cv2.resize(img,(0,0),fx=7,fy=7)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "invert = 255 - opening\n",
    "\n",
    "# im = img.filter(ImageFilter.MedianFilter())\n",
    "# enhancer = ImageEnhance.Contrast(im)\n",
    "# im = enhancer.enhance(2)\n",
    "# im = im.convert('1')\n",
    "# im.save('temp2.jpg')\n",
    "\n",
    "osd = pyt.image_to_osd(invert,output_type=\"dict\")\n",
    "print(osd)\n",
    "\n",
    "# cv2.imshow('thresh', thresh)\n",
    "# cv2.imshow('opening', opening)\n",
    "# cv2.imshow('invert', invert)\n",
    "# cv2.waitKey()\n",
    "\n",
    "page_text = pyt.image_to_string(invert, lang=\"Greek\",config=\"--psm 1 -c tessedit_ocr_engine_mode=1\")\n",
    "print(f\"OCR result for page 1: {page_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break PDF into one file per page (for troubleshooting marker)\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "\n",
    "goesin = \"base_test.pdf\"\n",
    "comesout = \"split_pdf\"\n",
    "\n",
    "def split_pdf(input_pdf, output_dir):\n",
    "    # Open the source PDF\n",
    "    doc = fitz.open(input_pdf)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over all pages\n",
    "    for page_num in range(len(doc)):\n",
    "        # Create a new PDF for each page\n",
    "        new_doc = fitz.open()\n",
    "        new_doc.insert_pdf(doc, from_page=page_num, to_page=page_num)\n",
    "\n",
    "        # Save with page number in filename (1-indexed for readability)\n",
    "        output_path = os.path.join(output_dir, f\"page_{page_num+1}.pdf\")\n",
    "        new_doc.save(output_path)\n",
    "        new_doc.close()\n",
    "\n",
    "        print(f\"Saved {output_path}\")\n",
    "\n",
    "    doc.close()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "split_pdf(goesin, comesout)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redaction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
