{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# import pytesseract as pyt\n",
    "import pymupdf\n",
    "# from pdf2image import convert_from_path\n",
    "# from PIL import Image, ImageEnhance, ImageFilter\n",
    "# import cv2\n",
    "# from tesserocr import PyTessBaseAPI, RIL\n",
    "# import tesserocr\n",
    "import json\n",
    "import pprint\n",
    "from dotenv import find_dotenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# marker functions\n",
    "from marker.converters.ocr import OCRConverter\n",
    "from marker.converters.pdf import PdfConverter\n",
    "from marker.models import create_model_dict\n",
    "from marker.config.parser import ConfigParser\n",
    "\n",
    "from importlib import reload as rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "    print(torch.cuda.get_device_properties(i).name) # Show existing GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marker testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import select_files, check_ok_for_marker\n",
    "\n",
    "# Read file-list to process\n",
    "pdf_files,json_files = select_files()\n",
    "\n",
    "# Verify files before uploading to marker or opening with PyMuPDF\n",
    "for selectfile in pdf_files.values():\n",
    "    check_ok_for_marker(selectfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MARKER CELL (for best performance run on Colab, or Ada/Hopper architectures)\n",
    "# jsondir = 'jsons_to_read'\n",
    "\n",
    "# marker_config = {\n",
    "#     \"output_format\": \"json\",\n",
    "#     \"OCRJSONRenderer_extract_images\": \"True\",\n",
    "#     \"disable_image_extraction\": \"True\",\n",
    "#     \"DEBUG\":\"True\",\n",
    "#     \"force_ocr\":\"True\",\n",
    "#     \"strip_existing_ocr\": \"True\"\n",
    "# }\n",
    "\n",
    "# config_parser = ConfigParser(marker_config)\n",
    "# converter = OCRConverter(   # OCR model for marker\n",
    "#     config=config_parser.generate_config_dict(),\n",
    "#     artifact_dict=create_model_dict(),\n",
    "# )\n",
    "\n",
    "# # remove this later, should be saving all jsons to \n",
    "# for markfile in pdf_files:\n",
    "#     rendered = converter(str(markfile))  # Run marker model\n",
    "#     output_filename = str(markfile.parents[1]) + \"\\\\\" + jsondir + \"\\\\\" + markfile.stem + \".json\"\n",
    "#     with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "#         f.write(rendered.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load JSON files corresponding to the selected PDFs. NOTE: this should be removed if patching straight through from marker-pdf\n",
    "\n",
    "renderedlist = {}\n",
    "for jname,jfile in json_files.items():\n",
    "    with open(jfile, \"r\", encoding=\"utf-8\") as f:\n",
    "        renderedlist.update({jname:json.load(f)['children']})\n",
    "\n",
    "for json_file in renderedlist.values():\n",
    "  pprint.pprint(json_file, indent=2)\n",
    "print(renderedlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve specific defined coordinates from JSON, \"flatten\" data\n",
    "from json_processing import ocr_retrieve_specific_boxes_and_flatten\n",
    "\n",
    "\n",
    "# Marker-defined categories (specifically leaves only) to extract from marker output JSON. Parse through the output JSON to find new leaf categories to add for extraction\n",
    "leaf_categories_with_text = ['Line','Text','TextInlineMath','Caption','ListItem','SectionHeader','TableCell', 'PageFooter','PageHeader']\n",
    "leaf_categories_to_retrieve = ['Picture','TableGroup','Equation', 'Figure', 'Handwriting']\n",
    "\n",
    "# NOTE: These are lists as we are dealing with multiple files, not just one. Do NOT change this architecture later down the line by mistake\n",
    "renderedboxes = {}\n",
    "renderedtext = {}\n",
    "\n",
    "for name in pdf_files.keys():\n",
    "\n",
    "  all_boxes,all_text = ocr_retrieve_specific_boxes_and_flatten(renderedlist[name],leaf_categories_to_retrieve,leaf_categories_with_text)\n",
    "  renderedboxes.update({name:all_boxes})\n",
    "  renderedtext.update({name:all_text})\n",
    "\n",
    "\n",
    "# sanity checks\n",
    "for name in pdf_files.keys():\n",
    "  display(renderedboxes[name])\n",
    "  display(renderedtext[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json_processing import transform_to_table\n",
    "\n",
    "\n",
    "lookup_table_main = {filename: transform_to_table(filename,renderedtext[filename],renderedboxes[filename]) for filename in pdf_files}\n",
    "\n",
    "for file_i in lookup_table_main.items():\n",
    "    print(file_i[0])\n",
    "    display(file_i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from tagging import ner_on_file\n",
    "\n",
    "# loads the sequence tagger\n",
    "tagger = SequenceTagger.load(\"pprokopidis/elNER18-bert-base-greek-uncased-v1-bs8-e150-lr5e-06\")\n",
    "\n",
    "# write code here to use the functions and retrieve the table\n",
    "ner_results = {filename:ner_on_file(table,tagger) for filename,table in lookup_table_main.items()}\n",
    "display(ner_results['test_text_and_signatures'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import merging\n",
    "rel(merging)\n",
    "\n",
    "filter_tags = []\n",
    "\n",
    "indexset = {filename:merging.get_index_set(table,lookup_table_main[filename][['page','totlength']],filter_tags) for filename,table in ner_results.items()}\n",
    "print(indexset)\n",
    "\n",
    "coordinates_to_redact = {filename:{page_num:lookup_table_main[filename].loc[list(indices),'coordinates'].tolist() for page_num,indices in indexdict.items()}  for filename,indexdict in indexset.items()}\n",
    "display(coordinates_to_redact['test_text_and_signatures'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from printing import redact_handwriting, add_boxes\n",
    "\n",
    "for filename,fileloc in pdf_files.items():\n",
    "   add_boxes(fileloc,coordinates_to_redact[filename])\n",
    "  #  redact_handwriting(filename,coordpack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write ALL coordinate boxes to entire PDF\n",
    "\n",
    "# def check_ok_to_write(filename):\n",
    "    \n",
    "#     doc = pymupdf.open(filename)\n",
    "\n",
    "#     if not doc.can_save_incrementally():\n",
    "\n",
    "#         print(f'File: \"{filename.stem}\" unwritable. Fixing...')\n",
    "\n",
    "#         new_file = str(filename.parent) + filename.stem + \"-fixed\" + \".pdf\"\n",
    "#         doc.save(new_file, garbage=4,deflate=True)\n",
    "#         doc.close()\n",
    "#         page=None\n",
    "#         os.remove(filename)\n",
    "#         os.rename(new_file,filename)\n",
    "#         doc = pymupdf.open(filename)\n",
    "#         return doc\n",
    "#     else:\n",
    "#         print('Nothing to fix!')\n",
    "#         return doc\n",
    "\n",
    "\n",
    "# def redact_handwriting(filename, redactions):\n",
    "\n",
    "#   doc = check_ok_to_write(filename)\n",
    "  \n",
    "#   for i,page in enumerate(doc):\n",
    "#     lines = redactions[i]\n",
    "#     nredactions = len(lines)\n",
    "#     for ncoord,coords in enumerate(lines.items()):\n",
    "#       print(f\"Page {i}: Adding annotation {ncoord} / {nredactions}\",end='\\r')\n",
    "#       if re.search(r\"(Handwriting)\",coords[0]):\n",
    "#         annot = page.add_redact_annot(coords[1],fill=(0,0,0))\n",
    "#         annot.update()\n",
    "#     page.apply_redactions()\n",
    "#     doc.saveIncr()\n",
    "#   doc.close()\n",
    "#   page=None\n",
    "#   print(f'\"{filename.stem}\" annotated.')\n",
    "\n",
    "\n",
    "\n",
    "# def add_boxes(filename, annotations):\n",
    "\n",
    "#   doc = check_ok_to_write(filename)\n",
    "  \n",
    "#   for i,page in enumerate(doc):\n",
    "#     lines = annotations[i]\n",
    "#     nannots = len(lines)\n",
    "#     for ncoord,coords in enumerate(lines.items()):\n",
    "#       print(f\"Page {i}: Adding annotation {ncoord} / {nannots}\",end='\\r')\n",
    "#       annot = page.add_polygon_annot(bbox_to_coords(coords[1]))\n",
    "#       annot.set_colors(stroke=(0.0431, 0.5882, 0.2509))\n",
    "#       annot.update()\n",
    "#       doc.saveIncr()\n",
    "#   doc.close()\n",
    "#   page=None\n",
    "#   print(f'\"{filename.stem}\" annotated.')\n",
    "\n",
    "\n",
    "# for name,boxes,texts in zip(pdf_files,renderedboxes,renderedtext):\n",
    "#   add_boxes(name, boxes)\n",
    "\n",
    "# # for name,boxes,texts in zip(pdf_files,renderedboxes,renderedtext):\n",
    "# #   redact_handwriting(name, boxes)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kofax: Pulling signatures from processed PDF \n",
    "(using Kofax, transform to Word and then back to PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, fitz, unicodedata\n",
    "\n",
    "# ---- helpers ---- \n",
    "def norm(s):\n",
    "    s = unicodedata.normalize('NFKC', str(s))\n",
    "    return s.replace('\\u00B7','.')  # middle dot → '.'\n",
    "\n",
    "# τίτλοι που ενεργοποιούν Wipe-Βand\n",
    "HEAD_TRIGGERS = [\n",
    "  'ΟΙ ΣΥΜΒΑΛΛΟΜΕΝΟΙ', 'Ο ΣΥΜΒΑΛΛΟΜΕΝΟΣ', 'Η ΣΥΜΒΑΛΛΟΜΕΝΗ',\n",
    "  'Ο ΣΥΝΕΤΑΙΡΟΣ ΠΙΣΤΟΥΧΟΣ', 'ΟΙ ΣΥΝΟΦΕΙΛΕΤΗΣ', 'Ο/ΟΙ ΣΥΝΟΦΕΙΛΕΤΗΣ/ΕΣ',\n",
    "  'Ο/ΟΙ ΕΓΓΥΗΤΗΣ/ΕΣ', 'Ο ΕΓΓΥΗΤΗΣ', 'Ο ΟΦΕΙΛΕΤΗΣ', 'Ο/ΟΙ ΟΦΕΙΛΕΤΗΣ/ΕΣ'\n",
    "]\n",
    "\n",
    "def text_blocks(page):\n",
    "    # rawdict → blocks (text/images) με bbox\n",
    "    data = page.get_text('rawdict')\n",
    "    return data.get('blocks', []) if isinstance(data, dict) else []\n",
    "\n",
    "def find_heading_band(page, side_margin=10, top_offset=6):\n",
    "    # ψάξε αν υπάρχει τίτλος-κλειδί στη σελίδα και γύρνα ζώνη (x0,y0,x1,y1)\n",
    "    W,H = page.rect.width, page.rect.height\n",
    "    best_y = None\n",
    "    for b in text_blocks(page):\n",
    "        if b.get('type') != 0: continue  # μόνο text blocks\n",
    "        for l in b.get('lines', []):\n",
    "            line_text = ' '.join([s.get('text','') for s in l.get('spans',[])])\n",
    "            T = norm(line_text).upper().strip()\n",
    "            for key in HEAD_TRIGGERS:\n",
    "                if key in T:\n",
    "                    # πάρε bbox της γραμμής\n",
    "                    xs=[]; ys=[]\n",
    "                    for s in l.get('spans', []):\n",
    "                        (x0,y0,x1,y1) = s.get('bbox', (None,None,None,None))\n",
    "                        if x0 is None: continue\n",
    "                        xs += [x0,x1]; ys += [y0,y1]\n",
    "                    if xs and ys:\n",
    "                        y_line = max(ys)  # κάτω άκρη γραμμής\n",
    "                        best_y = y_line if best_y is None else min(best_y, y_line)\n",
    "    if best_y is None: return None\n",
    "    x0 = page.rect.x0 + side_margin\n",
    "    y0 = best_y + top_offset\n",
    "    x1 = page.rect.x1 - side_margin\n",
    "    y1 = page.rect.y1 - 8\n",
    "    return (x0,y0,x1,y1) if y0 < y1 else None\n",
    "\n",
    "def image_boxes_in_band(page, band=None, bottom_ratio=0.35):\n",
    "    boxes = []\n",
    "    W,H = page.rect.width, page.rect.height\n",
    "    bottom_y = H*(1.0-bottom_ratio)\n",
    "    for b in text_blocks(page):\n",
    "        if b.get('type') == 1:  # image\n",
    "            (x0,y0,x1,y1) = b.get('bbox', (None,None,None,None))\n",
    "            if x0 is None: continue\n",
    "            # κριτήρια: (i) τέμνει band ή (ii) βρίσκεται στο κάτω Χ% της σελίδας\n",
    "            in_bottom = (y0 >= bottom_y) or (y1 >= bottom_y)\n",
    "            intersects_band = False\n",
    "            if band is not None:\n",
    "                bx0,by0,bx1,by1 = band\n",
    "                intersects_band = not (x1<bx0 or x0>bx1 or y1<by0 or y0>by1)\n",
    "            if intersects_band or in_bottom:\n",
    "                boxes.append((x0,y0,x1,y1))\n",
    "    return boxes\n",
    "\n",
    "def redact_pdf(input_pdf, output_pdf, do_wipe=True, do_images=True, side_margin=10, top_offset=6, bottom_ratio=0.35, fill='white', draw_labels=False):\n",
    "    rgb=(1,1,1) if str(fill).lower()=='white' else (0,0,0)\n",
    "    doc = fitz.open(input_pdf)\n",
    "    for pno in range(len(doc)):\n",
    "        page = doc[pno]\n",
    "        band = find_heading_band(page, side_margin=side_margin, top_offset=top_offset) if do_wipe else None\n",
    "        if band:\n",
    "            r = fitz.Rect(band)\n",
    "            page.add_redact_annot(r, text=('[SIGN-BAND]' if draw_labels else None), fill=rgb)\n",
    "        if do_images:\n",
    "            for (x0,y0,x1,y1) in image_boxes_in_band(page, band=band, bottom_ratio=bottom_ratio):\n",
    "                r = fitz.Rect(x0,y0,x1,y1)\n",
    "                page.add_redact_annot(r, text=('[IMG]' if draw_labels else None), fill=rgb)\n",
    "        page.apply_redactions()\n",
    "    doc.save(output_pdf, garbage=4, deflate=True)\n",
    "    doc.close()\n",
    "\n",
    "\n",
    "redact_pdf('test_text_and_signaturesdoc.pdf',\"out_signzones.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure: DocumentIntelligence for OCR\n",
    "\n",
    "and integrating an NER model on the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path='./config/.env')\n",
    "\n",
    "AZURE_ENDPOINT = os.getenv('AZURE_ENDPOINT')\n",
    "AZURE_KEY = os.getenv('AZURE_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_CONFIG = {\n",
    "    \"endpoint\" : AZURE_ENDPOINT,\n",
    "    \"key\" : AZURE_KEY\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TesserOCR: Testing library to get coordinates\n",
    "\n",
    "After pre-OCR-ing with Tungsten/Kofax PowerPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Tesseract + output images (i think)\n",
    "\n",
    "# Define Tesseract exe location\n",
    "pyt.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "pyt.get_languages()\n",
    "\n",
    "current_file = \"testtest.pdf\"\n",
    "\n",
    "\n",
    "\n",
    "def ocr_scanned_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    images = convert_from_path(pdf_path)    \n",
    "    for i, image in enumerate(images):\n",
    "        page_text = pyt.image_to_string(image, lang=\"ell\",config=\"--psm 4 --oem 3 -c tessedit_write_images=true\")      \n",
    "        print(f\"OCR result for page {i+1}: {page_text}\")\n",
    "        # text += f\"--- Page {i+1} ---\\n{page_text}\\n\\n\"\n",
    "    return text\n",
    "\n",
    "\n",
    "ocr_scanned_pdf(current_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite initial file to contain all coordinates of identified words\n",
    "\n",
    "\n",
    "insertions = []\n",
    "\n",
    "# open document\n",
    "input_pdf = \"testtest.pdf\"\n",
    "doc = fitz.open(input_pdf)\n",
    "\n",
    "# insert here transform pdf to image\n",
    "images = convert_from_path(input_pdf)\n",
    "print(images)\n",
    "\n",
    "\n",
    "def transform_coords(box):\n",
    "    # assume of dict format with {'x':x,'y':y,'w':w,'h':h}\n",
    "    x1 = box['x']\n",
    "    y1 = box['y']\n",
    "    w = box['w']\n",
    "    h = box['h']\n",
    "    x2 = x1+w\n",
    "    y2 = y1+h\n",
    "\n",
    "    # with polygon annotation:\n",
    "    coordinates_pdf = [(x1*scale_x - 2,y1*scale_y - 2),(x2*scale_x + 2,y1*scale_y - 2), (x2*scale_x + 2,y2*scale_y + 2),(x1*scale_x - 2,y2*scale_y + 2)]\n",
    "\n",
    "    # with redact annotation:\n",
    "\n",
    "\n",
    "    return coordinates_pdf\n",
    "\n",
    "\n",
    "for j,image in enumerate(images):\n",
    "\n",
    "    insertions_temp_dict = {}\n",
    "\n",
    "    with PyTessBaseAPI(path=r'C:\\Program Files\\Tesseract-OCR\\tessdata', lang='ell') as api:\n",
    "\n",
    "\n",
    "        api.SetImage(image)\n",
    "\n",
    "        # get all sizes\n",
    "        currentpage = j\n",
    "        imgsize = image.size\n",
    "        page = doc[currentpage]\n",
    "        scale_x = page.rect.width / imgsize[0]\n",
    "        scale_y = page.rect.height / imgsize[1]\n",
    "\n",
    "        boxes = api.GetComponentImages(RIL.TEXTLINE, True)\n",
    "        total_items = len(boxes)\n",
    "        print('Found {} textline image components.'.format(total_items))\n",
    "        for i, (im, box, _, _) in enumerate(boxes):\n",
    "\n",
    "            api.SetRectangle(box['x'], box['y'], box['w'], box['h'])\n",
    "            ocrResult = api.GetUTF8Text()\n",
    "            conf = api.MeanTextConf()\n",
    "\n",
    "            # create box visually on PDF and add embellishments\n",
    "            pdf_transformed_coordinates = transform_coords(box)\n",
    "            # print(pdf_transformed_coordinates)\n",
    "            print(pdf_transformed_coordinates)\n",
    "            annot = page.add_polygon_annot(pdf_transformed_coordinates)\n",
    "            annot.set_colors(stroke=(0.416, 0.416, 1))\n",
    "            annot.update()\n",
    "\n",
    "            # # add text for visual representation\n",
    "            # text_rect = fitz.Rect(pdf_transformed_coordinates[0][0],pdf_transformed_coordinates[0][1],pdf_transformed_coordinates[2][0],pdf_transformed_coordinates[2][1])\n",
    "            # # text_rect = fitz.Rect(100,100,100,100)\n",
    "            # page.insert_textbox(\n",
    "            #     text_rect,\n",
    "            #     ocrResult,\n",
    "            #     fontsize=3,\n",
    "            #     fontname=\"helv\",\n",
    "            #     color=(0, 0, 0),   # black text\n",
    "            #     align=1            # center align\n",
    "            # )\n",
    "\n",
    "            # insertions_temp_dict.update({i:inserted})\n",
    "            doc.saveIncr()\n",
    "            print(f\"\\rProgress: {i+1}/{total_items}\",\"\\r\",end=\"\")\n",
    "    insertions.append(insertions_temp_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "doc.close()\n",
    "page = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear document from all annotations\n",
    "def clear_doc(filename,filedir):\n",
    "\n",
    "\n",
    "\n",
    "    init_file = filedir + filename + \".pdf\"\n",
    "    doc = pymupdf.open(init_file)\n",
    "    page = doc[0]\n",
    "    for annot in page.annots():\n",
    "        page.delete_annot(annot)\n",
    "    doc.saveIncr()\n",
    "    doc.close()\n",
    "    page=None\n",
    "\n",
    "clear_doc(\"page1test\",\"./docs_to_write_on/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redact/Annotate specific coordinates\n",
    "\n",
    "def redact_pdf(filename,filedir, coords):\n",
    "    init_file = filedir + filename + \".pdf\"\n",
    "    doc = fitz.open(init_file)\n",
    "    for page in doc:\n",
    "        print(page.rect.width,page.rect.height)\n",
    "        page.add_redact_annot(coords, fill=(0, 0, 0))\n",
    "    doc.save(\"output1.pdf\")\n",
    "    doc.close()\n",
    "\n",
    "\n",
    "def annotate_specific_coords(filename,filedir,coords,colour):\n",
    "    init_file = filedir + filename + \".pdf\"\n",
    "    doc = pymupdf.open(init_file)\n",
    "    page = doc[0]\n",
    "    annot = page.add_polygon_annot(coords)\n",
    "    annot.set_colors(stroke=colour)\n",
    "    annot.update()\n",
    "    doc.saveIncr()\n",
    "    doc.close()\n",
    "    page=None\n",
    "\n",
    "\n",
    "for spacetem in blanks:\n",
    "    specific_annot =  spacetem\n",
    "    paint = (0,0,1)\n",
    "    # (0.416, 0.416, 1)\n",
    "\n",
    "    annotate_specific_coords(\"page1test\",\"./docs_to_write_on/\",specific_annot,paint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quickly turn PDF to images\n",
    "\n",
    "pages = convert_from_path(current_file)\n",
    "for count, page in enumerate(pages):\n",
    "    page.save(f'out{count}.jpg', 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF/Image pre-processing to improve Tesseract results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# img = Image.open(\"./testactual_page-0001.jpg\")\n",
    "# print(img)\n",
    "# osd = pyt.image_to_osd(img,output_type=\"dict\")\n",
    "# print(osd)\n",
    "\n",
    "\n",
    "img = cv2.imread(\"./out0.jpg\")\n",
    "img = cv2.resize(img,(0,0),fx=7,fy=7)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "invert = 255 - opening\n",
    "\n",
    "# im = img.filter(ImageFilter.MedianFilter())\n",
    "# enhancer = ImageEnhance.Contrast(im)\n",
    "# im = enhancer.enhance(2)\n",
    "# im = im.convert('1')\n",
    "# im.save('temp2.jpg')\n",
    "\n",
    "osd = pyt.image_to_osd(invert,output_type=\"dict\")\n",
    "print(osd)\n",
    "\n",
    "# cv2.imshow('thresh', thresh)\n",
    "# cv2.imshow('opening', opening)\n",
    "# cv2.imshow('invert', invert)\n",
    "# cv2.waitKey()\n",
    "\n",
    "page_text = pyt.image_to_string(invert, lang=\"Greek\",config=\"--psm 1 -c tessedit_ocr_engine_mode=1\")\n",
    "print(f\"OCR result for page 1: {page_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break PDF into one file per page (for troubleshooting marker)\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "\n",
    "goesin = \"base_test.pdf\"\n",
    "comesout = \"split_pdf\"\n",
    "\n",
    "def split_pdf(input_pdf, output_dir):\n",
    "    # Open the source PDF\n",
    "    doc = fitz.open(input_pdf)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over all pages\n",
    "    for page_num in range(len(doc)):\n",
    "        # Create a new PDF for each page\n",
    "        new_doc = fitz.open()\n",
    "        new_doc.insert_pdf(doc, from_page=page_num, to_page=page_num)\n",
    "\n",
    "        # Save with page number in filename (1-indexed for readability)\n",
    "        output_path = os.path.join(output_dir, f\"page_{page_num+1}.pdf\")\n",
    "        new_doc.save(output_path)\n",
    "        new_doc.close()\n",
    "\n",
    "        print(f\"Saved {output_path}\")\n",
    "\n",
    "    doc.close()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "split_pdf(goesin, comesout)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
