import re
from bs4 import BeautifulSoup
import pathlib
import pandas as pd
import numpy as np




def clean_text(inputhtml: str) -> str:
  return re.sub('[.]{2,}',"",BeautifulSoup(inputhtml, "html.parser").get_text(strip=True))

def bbox_to_coords(bbox: list) -> list:
   return [(bbox[0],bbox[1]),(bbox[2],bbox[1]),(bbox[2],bbox[3]),(bbox[0],bbox[3])]



def ocr_retrieve_specific_boxes_and_flatten(treelist:list[dict],pull_polygons:list[str],pull_text:list[str]) -> tuple:
  """Retrieve all coordinates and text of objects identified by marker-pdf. This function
  works recursively to traverse the tree-like dictionary item (JSON format), picking up specific information
  (bounding box coordinates and text) from leaf nodes on the tree, with categories specified by 

  :param treelist: List of JSON files read into python, outputs of marker-pdf.
   Also takes JSON formats returned from the marker OCRConverter with 
   the --keep-chars flag active

  :param pull_polygons: List of names ('block_type') of objects generated by marker-pdf, from which you want to retrieve
   bounding box coordinates. These are pulled from the treelist argument.

  :param pull_text: List of names ('block_type') of objects generated by marker-pdf, from which you want to retrieve
   HTML text. These are pulled from the treelist argument.
  """
  coordinates = {}
  htmtext = {}
  
  for nitem,item in enumerate(treelist):
    newpoly = {}  # create dicts to store 
    newtext = {}
    if (item['block_type'] == 'Char'):  # first check if this is a 'Char' object (i.e. --keep-chars flag active and we have individual characters. these don't have a 'children' child node so we check to not break the function)
        newpoly = item['bbox']
        newitem_poly = {item['id']:newpoly}
        newtext = item['text']
        newitem_text = {item['id']:newtext}
    else:   # if not 'Char', proceed a for a normal node
        if (item['children']):  # if node has children, retrieve them all and keep them to add to main dict later
            newchildren = item['children']
            retr_coords,retr_text = ocr_retrieve_specific_boxes_and_flatten(newchildren,pull_polygons,pull_text)
            newpoly.update(retr_coords)
            newtext.update(retr_text)
            if item['block_type']=='Page':  # specifically if the item is a page, also keep the page number, and add the children in a sub-dictionary. This nests the dictionary page-wise, keeping all page items separate according to their page of origin
                # newitem_poly = newpoly
                # newitem_text = newtext
                newitem_poly = {int(re.search(r"/page/(\d+)/", item['id']).group(1)):newpoly}
                newitem_text = {int(re.search(r"/page/(\d+)/", item['id']).group(1)):newtext}
            else:   # if the item isn't a page, don't nest the items and add them alongside the rest, on the same level
                newitem_poly = newpoly
                newitem_text = newtext
        else:   # if the node doesn't have children, then we must be in a leaf node
            if (item['block_type'] in pull_polygons) or (item['block_type'] in pull_text):   # check if the current node is one we want to retrieve (from the pre-defined categories), and if so get text and bbox coordinates
                newpoly = item['bbox']
                newitem_poly = {item['id']:newpoly}
                if item['block_type'] in pull_text:   # 
                    newtext = clean_text(item['html'])
                    if not newtext: continue  # this is here to clean out any empty strings. if anything causes an issue down the line, it'll be this. removed items *should* be read lines that consist solely of dots
                    newitem_text = {item['id']:newtext}
                else:
                    newitem_text = {}
            else: 
                newitem_poly = {}
                newitem_text = {}
    coordinates.update(newitem_poly)
    htmtext.update(newitem_text)
  return (coordinates,htmtext)



def transform_to_table(filename:pathlib.Path,filetext: dict[dict],filebox:dict[dict]) -> pd.DataFrame:




    #NOTE SOS: Since we are doing a join and adding one whitespace, we need to take it into account when counting the sentence length in the OG datatable, so EACH
    # row's totlength is increased by 1 to account for this and match up with the syntok tokens later, hence the +1 in totlength

    build_df = pd.concat([pd.DataFrame({'page' : [pagetext[0] for identifier in pagetext[1].keys()],
                                        'line' : [int(re.search(r"/page/[\d+]/Line/(\d+)", identifier).group(1)) for identifier in pagetext[1].keys()],
                                        'length' : [len(readline) for readline in pagetext[1].values()],
                                        'totlength' :  np.cumsum([len(readline)+1 for readline in pagetext[1].values()]).tolist(),
                                        'text' : [readline for readline in pagetext[1].values()],
                                        'coordinates' : [box for box in pagebox.values()]
                                        }) for pagetext,pagebox in zip(filetext.items(),filebox.values())], ignore_index=True)
    
    return build_df